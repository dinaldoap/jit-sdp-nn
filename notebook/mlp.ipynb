{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JIT-SDP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dinaldoap/jit-sdp-nn/blob/master/notebook/mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import random\n",
        "from scipy.stats import mstats\n",
        "\n",
        "from jitsdp import metrics\n",
        "from jitsdp.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fix</th>\n      <th>ns</th>\n      <th>nd</th>\n      <th>nf</th>\n      <th>entrophy</th>\n      <th>la</th>\n      <th>ld</th>\n      <th>lt</th>\n      <th>ndev</th>\n      <th>age</th>\n      <th>nuc</th>\n      <th>exp</th>\n      <th>rexp</th>\n      <th>sexp</th>\n      <th>contains_bug</th>\n      <th>author_date_unix_timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>False</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>202</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>True</td>\n      <td>1293840523</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>False</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.784992</td>\n      <td>28</td>\n      <td>19</td>\n      <td>103.0</td>\n      <td>1</td>\n      <td>-244.640741</td>\n      <td>3</td>\n      <td>3.5</td>\n      <td>0.996934</td>\n      <td>4</td>\n      <td>True</td>\n      <td>1293853015</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>False</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>84</td>\n      <td>22</td>\n      <td>189.0</td>\n      <td>1</td>\n      <td>-244.640613</td>\n      <td>4</td>\n      <td>7.0</td>\n      <td>0.995912</td>\n      <td>7</td>\n      <td>True</td>\n      <td>1293857524</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>True</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>8</td>\n      <td>7</td>\n      <td>251.0</td>\n      <td>1</td>\n      <td>2.775000</td>\n      <td>5</td>\n      <td>8.0</td>\n      <td>1.360360</td>\n      <td>8</td>\n      <td>True</td>\n      <td>1294097284</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>False</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>205</td>\n      <td>79</td>\n      <td>252.0</td>\n      <td>1</td>\n      <td>0.174444</td>\n      <td>6</td>\n      <td>9.0</td>\n      <td>6.732484</td>\n      <td>9</td>\n      <td>True</td>\n      <td>1294112356</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "     fix  ns  nd  nf  entrophy   la  ld     lt  ndev         age  nuc  exp  \\\n0  False   1   1   1  0.000000  202   0    0.0     1    0.000000    0  0.0   \n1  False   1   2   2  0.784992   28  19  103.0     1 -244.640741    3  3.5   \n2  False   1   1   1  0.000000   84  22  189.0     1 -244.640613    4  7.0   \n3   True   1   1   1  0.000000    8   7  251.0     1    2.775000    5  8.0   \n4  False   1   1   1  0.000000  205  79  252.0     1    0.174444    6  9.0   \n\n       rexp  sexp  contains_bug  author_date_unix_timestamp  \n0  0.000000     0          True                  1293840523  \n1  0.996934     4          True                  1293853015  \n2  0.995912     7          True                  1293857524  \n3  1.360360     8          True                  1294097284  \n4  6.732484     9          True                  1294112356  "
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/dinaldoap/jit-sdp-data/master/neutron.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "/home/pytorch/.conda/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \"\"\"\n"
        }
      ],
      "source": [
        "#df = df.sample(frac=1)\n",
        "label_col = 'contains_bug'\n",
        "features_cols = ['fix', 'ns', 'nd', 'nf', 'entrophy', 'la', 'ld', 'lt', 'ndev', 'age', 'nuc', 'exp', 'rexp', 'sexp']\n",
        "X = df[features_cols]\n",
        "X['fix'] = X['fix'].astype('int')\n",
        "X = X.values\n",
        "y = df[label_col]\n",
        "y = y.astype('int')\n",
        "y = y.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "[[  0.   1.   1.   1.   0. 202.   0.   0.   1.   0.   0.   0.   0.   0.]]\n[1]\n"
        }
      ],
      "source": [
        "print(X[:1])\n",
        "print(y[:1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_index = int( len(X) * 0.8 )\n",
        "X_train, y_train = X[:test_index], y[:test_index]\n",
        "X_test, y_test = X[test_index:], y[test_index:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "[[  0.   1.   1.   1.   0. 202.   0.   0.   1.   0.   0.   0.   0.   0.]]\n[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
        }
      ],
      "source": [
        "print(X_train[:1])\n",
        "print(X_test[:1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "mean_train = X_train.mean(axis=0)\n",
        "std_train = X_train.std(axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "[2.24691042e-01 6.37126209e-01 2.21239675e+00 3.14484216e+00\n 5.99416261e-01 2.69237754e+02 2.51954601e+02 4.93221171e+02\n 7.02866748e+01 1.66493700e+01 8.44467567e+01 2.35551162e+02\n 1.98825516e+00 1.46978805e+02]\n[4.17378698e-01 6.99005149e-01 7.14876580e+00 1.59028200e+01\n 1.07509921e+00 3.76885765e+03 9.01027281e+03 1.59901257e+03\n 8.14342402e+01 5.24819955e+01 4.52271552e+02 6.40880725e+02\n 2.86627928e+01 4.81337683e+02]\n"
        }
      ],
      "source": [
        "print(mean_train)\n",
        "print(std_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = (X_train - mean_train) / std_train\n",
        "X_test = (X_test - mean_train) / std_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "[[-0.53833855  0.51912893 -0.16959525 -0.13487181 -0.55754507 -0.01784035\n  -0.02796304 -0.30845359 -0.85082976 -0.31723965 -0.18671693 -0.3675429\n  -0.06936711 -0.30535487]]\n[[-0.53833855 -0.9114757  -0.30947954 -0.19775374 -0.55754507 -0.0714375\n  -0.02796304 -0.30845359 -0.8631096  -0.31723965 -0.18671693 -0.3675429\n  -0.06936711 -0.30535487]]\n"
        }
      ],
      "source": [
        "print(X_train[:1])\n",
        "print(X_test[:1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Classifier(nn.Module):\n",
        "  FILENAME = 'models/classifier.cpt'\n",
        "  def __init__(self, input_size, hidden_size, drop_prob, epoch=None, val_gmean=None):\n",
        "    super(Classifier, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.drop_prob = drop_prob\n",
        "    self.epoch = epoch\n",
        "    self.val_gmean = val_gmean\n",
        "    self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "    self.fcout = nn.Linear(hidden_size, 1)\n",
        "    self.dropout = nn.Dropout(drop_prob)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = torch.sigmoid(self.fc1(x))\n",
        "    x = self.dropout(x)\n",
        "    x = torch.sigmoid(self.fcout(x))\n",
        "    return x\n",
        "\n",
        "  def save(self):\n",
        "    checkpoint = {\n",
        "        'input_size': self.input_size,\n",
        "        'hidden_size': self.hidden_size,\n",
        "        'drop_prob': self.drop_prob,\n",
        "        'val_gmean': self.val_gmean,\n",
        "        'epoch': self.epoch,\n",
        "        'state_dict': self.state_dict()\n",
        "    }\n",
        "    with open(Classifier.FILENAME, 'wb') as f:\n",
        "      torch.save(checkpoint, f)\n",
        "\n",
        "  def load(self):\n",
        "    with open(Classifier.FILENAME, 'rb') as f:\n",
        "      checkpoint = torch.load(f)\n",
        "      self.input_size = checkpoint['input_size']\n",
        "      self.hidden_size = checkpoint['hidden_size']\n",
        "      self.drop_prob = checkpoint['drop_prob']\n",
        "      self.epoch = checkpoint['epoch']\n",
        "      self.val_gmean = checkpoint['val_gmean']\n",
        "      self.load_state_dict(checkpoint['state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": "Classifier(\n  (fc1): Linear(in_features=14, out_features=14, bias=True)\n  (fcout): Linear(in_features=14, out_features=1, bias=True)\n  (dropout): Dropout(p=0.5, inplace=False)\n)"
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier = Classifier(input_size=X.shape[1], hidden_size=X.shape[1], drop_prob=0.5)\n",
        "classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": "Classifier(\n  (fc1): Linear(in_features=14, out_features=14, bias=True)\n  (fcout): Linear(in_features=14, out_features=1, bias=True)\n  (dropout): Dropout(p=0.5, inplace=False)\n)"
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier.save()\n",
        "classifier.load()\n",
        "classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [],
      "source": [
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(params=classifier.parameters(), lr=0.003)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Epoch: 0, Train loss: 0.6779607976636579, Train g-mean: 0.7947875166708793, Val g-mean: None\nEpoch: 1, Train loss: 0.6433510313917273, Train g-mean: 0.8006652655553956, Val g-mean: None\nEpoch: 2, Train loss: 0.5864819253980763, Train g-mean: 0.7984759125788846, Val g-mean: None\nEpoch: 3, Train loss: 0.540752310796129, Train g-mean: 0.8051761963339, Val g-mean: None\nEpoch: 4, Train loss: 0.5130252805846849, Train g-mean: 0.8114405440767896, Val g-mean: None\nEpoch: 5, Train loss: 0.49540114488492065, Train g-mean: 0.8137587267175546, Val g-mean: None\nEpoch: 6, Train loss: 0.48267534377955934, Train g-mean: 0.8175515545055543, Val g-mean: None\nEpoch: 7, Train loss: 0.477035810871401, Train g-mean: 0.8167988784043516, Val g-mean: None\nEpoch: 8, Train loss: 0.4717389024817648, Train g-mean: 0.819638936646194, Val g-mean: None\nEpoch: 9, Train loss: 0.46684741582128214, Train g-mean: 0.8200116394325693, Val g-mean: None\nEpoch: 10, Train loss: 0.446046743535756, Train g-mean: 0.8212442584792505, Val g-mean: None\nEpoch: 11, Train loss: 0.4552213243176783, Train g-mean: 0.8219381227459763, Val g-mean: None\nEpoch: 12, Train loss: 0.4365750176019894, Train g-mean: 0.8219372473793888, Val g-mean: None\nEpoch: 13, Train loss: 0.43112288823149353, Train g-mean: 0.8224391876274932, Val g-mean: None\nEpoch: 14, Train loss: 0.42984105563625913, Train g-mean: 0.8235252533997462, Val g-mean: None\nEpoch: 15, Train loss: 0.43102689853806175, Train g-mean: 0.8238821041945981, Val g-mean: None\nEpoch: 16, Train loss: 0.4241487477644473, Train g-mean: 0.8243456612974613, Val g-mean: None\nEpoch: 17, Train loss: 0.41529597228068243, Train g-mean: 0.82453839565534, Val g-mean: None\nEpoch: 18, Train loss: 0.4201160145015159, Train g-mean: 0.8257148617073666, Val g-mean: None\nEpoch: 19, Train loss: 0.4106479923962606, Train g-mean: 0.8262331439403116, Val g-mean: None\nEpoch: 20, Train loss: 0.40929570230437556, Train g-mean: 0.8321399790167818, Val g-mean: None\nEpoch: 21, Train loss: 0.4051301150657135, Train g-mean: 0.8350762594412534, Val g-mean: None\nEpoch: 22, Train loss: 0.40528780404322057, Train g-mean: 0.8364941578179562, Val g-mean: None\nEpoch: 23, Train loss: 0.40148763604817617, Train g-mean: 0.8383689431297907, Val g-mean: None\nEpoch: 24, Train loss: 0.399817347125295, Train g-mean: 0.8396726951010305, Val g-mean: None\nEpoch: 25, Train loss: 0.40191520220477367, Train g-mean: 0.8403550529744451, Val g-mean: None\nEpoch: 26, Train loss: 0.39808493018356667, Train g-mean: 0.8418235609490038, Val g-mean: None\nEpoch: 27, Train loss: 0.3894370253240574, Train g-mean: 0.8421926391887375, Val g-mean: None\nEpoch: 28, Train loss: 0.39192425453328156, Train g-mean: 0.843245425732266, Val g-mean: None\nEpoch: 29, Train loss: 0.3943752365226589, Train g-mean: 0.8438972216442053, Val g-mean: None\nEpoch: 30, Train loss: 0.3894571229876852, Train g-mean: 0.8445626543574246, Val g-mean: None\nEpoch: 31, Train loss: 0.39278351063709677, Train g-mean: 0.8450710829329944, Val g-mean: None\nEpoch: 32, Train loss: 0.3839563213994366, Train g-mean: 0.8461969481281327, Val g-mean: None\nEpoch: 33, Train loss: 0.38715806149414234, Train g-mean: 0.8466245630056639, Val g-mean: None\nEpoch: 34, Train loss: 0.38178360928225613, Train g-mean: 0.8471609772574564, Val g-mean: None\nEpoch: 35, Train loss: 0.3875089385397742, Train g-mean: 0.8476588503660757, Val g-mean: None\nEpoch: 36, Train loss: 0.3801195470821714, Train g-mean: 0.8475313016725166, Val g-mean: None\nEpoch: 37, Train loss: 0.3810309685953581, Train g-mean: 0.848100532651334, Val g-mean: None\nEpoch: 38, Train loss: 0.3776362526086329, Train g-mean: 0.8485488962274532, Val g-mean: None\nEpoch: 39, Train loss: 0.37658732068047523, Train g-mean: 0.8485947337028699, Val g-mean: None\nEpoch: 40, Train loss: 0.38381885294360035, Train g-mean: 0.8495498115674802, Val g-mean: None\nEpoch: 41, Train loss: 0.381073661967068, Train g-mean: 0.8496560754459773, Val g-mean: None\nEpoch: 42, Train loss: 0.3805315208795234, Train g-mean: 0.8493677026683683, Val g-mean: None\nEpoch: 43, Train loss: 0.38091737612717436, Train g-mean: 0.8508299690336677, Val g-mean: None\nEpoch: 44, Train loss: 0.3761178199272749, Train g-mean: 0.8489445017234788, Val g-mean: None\nEpoch: 45, Train loss: 0.3685121640204787, Train g-mean: 0.8492564346547536, Val g-mean: None\nEpoch: 46, Train loss: 0.37361962694198664, Train g-mean: 0.8497127669728297, Val g-mean: None\nEpoch: 47, Train loss: 0.3773893948198233, Train g-mean: 0.8489881474446423, Val g-mean: None\nEpoch: 48, Train loss: 0.37867389646845756, Train g-mean: 0.8492681285506446, Val g-mean: None\nEpoch: 49, Train loss: 0.3715239229790875, Train g-mean: 0.8517889488077763, Val g-mean: None\nEpoch: 50, Train loss: 0.37264623200698727, Train g-mean: 0.8531380578578824, Val g-mean: None\nEpoch: 51, Train loss: 0.37039487174627733, Train g-mean: 0.8531697291447339, Val g-mean: None\nEpoch: 52, Train loss: 0.37067619402289315, Train g-mean: 0.8530830760411315, Val g-mean: None\nEpoch: 53, Train loss: 0.3668341666905726, Train g-mean: 0.8518490622145307, Val g-mean: None\nEpoch: 54, Train loss: 0.3692245734329142, Train g-mean: 0.8519573083471997, Val g-mean: None\nEpoch: 55, Train loss: 0.3736469926776268, Train g-mean: 0.8526806812021461, Val g-mean: None\nEpoch: 56, Train loss: 0.37079735399042973, Train g-mean: 0.8520949063975563, Val g-mean: None\nEpoch: 57, Train loss: 0.37286587453681785, Train g-mean: 0.8510005182081697, Val g-mean: None\nEpoch: 58, Train loss: 0.37058837532253625, Train g-mean: 0.851692481601999, Val g-mean: None\nEpoch: 59, Train loss: 0.37287549668718784, Train g-mean: 0.8523517575361546, Val g-mean: None\nEpoch: 60, Train loss: 0.37002668793937515, Train g-mean: 0.8522833926108567, Val g-mean: None\nEpoch: 61, Train loss: 0.3644898354417345, Train g-mean: 0.8518677360198522, Val g-mean: None\nEpoch: 62, Train loss: 0.3621550292718996, Train g-mean: 0.8509034676096582, Val g-mean: None\nEpoch: 63, Train loss: 0.37153638399720385, Train g-mean: 0.8515636958232659, Val g-mean: None\nEpoch: 64, Train loss: 0.3714844116591254, Train g-mean: 0.8537708300334167, Val g-mean: None\nEpoch: 65, Train loss: 0.3657422358279037, Train g-mean: 0.8504391529610139, Val g-mean: None\nEpoch: 66, Train loss: 0.3628248975946205, Train g-mean: 0.8510553659430232, Val g-mean: None\nEpoch: 67, Train loss: 0.36878817250098495, Train g-mean: 0.8520805556132588, Val g-mean: None\nEpoch: 68, Train loss: 0.36414734072895644, Train g-mean: 0.8510831789047094, Val g-mean: None\nEpoch: 69, Train loss: 0.36539196889484177, Train g-mean: 0.8522326472240414, Val g-mean: None\nEpoch: 70, Train loss: 0.36534732289240057, Train g-mean: 0.8511286515146472, Val g-mean: None\nEpoch: 71, Train loss: 0.36030426419778705, Train g-mean: 0.8502880412607758, Val g-mean: None\nEpoch: 72, Train loss: 0.36483763296021055, Train g-mean: 0.8501700392858944, Val g-mean: None\nEpoch: 73, Train loss: 0.36550610733244143, Train g-mean: 0.8515857727846629, Val g-mean: None\nEpoch: 74, Train loss: 0.36238425664754753, Train g-mean: 0.8516137470537566, Val g-mean: None\nEpoch: 75, Train loss: 0.35714925767678474, Train g-mean: 0.850792533482526, Val g-mean: None\nEpoch: 76, Train loss: 0.3602798681879872, Train g-mean: 0.8506499051396859, Val g-mean: None\nEpoch: 77, Train loss: 0.3788776785501384, Train g-mean: 0.8512680151945213, Val g-mean: None\nEpoch: 78, Train loss: 0.36367411892378376, Train g-mean: 0.8505092821264205, Val g-mean: None\nEpoch: 79, Train loss: 0.3712764483244073, Train g-mean: 0.8512143576796086, Val g-mean: None\nEpoch: 80, Train loss: 0.3658092486651702, Train g-mean: 0.8517378118111248, Val g-mean: None\nEpoch: 81, Train loss: 0.3770764100544939, Train g-mean: 0.8505152917646484, Val g-mean: None\nEpoch: 82, Train loss: 0.36538454963312766, Train g-mean: 0.8518337648913611, Val g-mean: None\nEpoch: 83, Train loss: 0.3662394766120328, Train g-mean: 0.8507600392574574, Val g-mean: None\nEpoch: 84, Train loss: 0.3660494306526781, Train g-mean: 0.8501993448525014, Val g-mean: None\nEpoch: 85, Train loss: 0.36719418218969724, Train g-mean: 0.8498458458828768, Val g-mean: None\nEpoch: 86, Train loss: 0.34883906689101635, Train g-mean: 0.8499144648449399, Val g-mean: None\nEpoch: 87, Train loss: 0.36250676430900064, Train g-mean: 0.8505823330496589, Val g-mean: None\nEpoch: 88, Train loss: 0.36502405479314476, Train g-mean: 0.851061363967137, Val g-mean: None\nEpoch: 89, Train loss: 0.35736772689600227, Train g-mean: 0.8501624981133384, Val g-mean: None\nEpoch: 90, Train loss: 0.3596314433035605, Train g-mean: 0.849894279390681, Val g-mean: None\nEpoch: 91, Train loss: 0.35149868150814034, Train g-mean: 0.8502446038059165, Val g-mean: None\nEpoch: 92, Train loss: 0.3687665227985714, Train g-mean: 0.8516606527392232, Val g-mean: None\nEpoch: 93, Train loss: 0.36120124037527374, Train g-mean: 0.8499835070609094, Val g-mean: None\nEpoch: 94, Train loss: 0.36401371942267086, Train g-mean: 0.8489752071090622, Val g-mean: None\nEpoch: 95, Train loss: 0.35576247553232704, Train g-mean: 0.8497025105666249, Val g-mean: None\nEpoch: 96, Train loss: 0.3644985756503008, Train g-mean: 0.8515341758379772, Val g-mean: None\nEpoch: 97, Train loss: 0.36221813835516564, Train g-mean: 0.8505437641715381, Val g-mean: None\nEpoch: 98, Train loss: 0.3627470557657028, Train g-mean: 0.8506806307550264, Val g-mean: None\nEpoch: 99, Train loss: 0.3719908945174856, Train g-mean: 0.849613380801086, Val g-mean: None\nEpoch: 100, Train loss: 0.3681425550048449, Train g-mean: 0.8495761416596472, Val g-mean: None\nEpoch: 101, Train loss: 0.36000677013418014, Train g-mean: 0.8487150951865918, Val g-mean: None\nEpoch: 102, Train loss: 0.3688260025439791, Train g-mean: 0.8483618046319762, Val g-mean: None\nEpoch: 103, Train loss: 0.37046673511516065, Train g-mean: 0.8504254938420938, Val g-mean: None\nEpoch: 104, Train loss: 0.36315350270240887, Train g-mean: 0.8499702329460149, Val g-mean: None\nEpoch: 105, Train loss: 0.3577976885457095, Train g-mean: 0.8506465652994485, Val g-mean: None\nEpoch: 106, Train loss: 0.3632424619986782, Train g-mean: 0.8518322714881817, Val g-mean: None\nEpoch: 107, Train loss: 0.36075469321843806, Train g-mean: 0.8507289454255227, Val g-mean: None\nEpoch: 108, Train loss: 0.3608901412470485, Train g-mean: 0.8510672119861958, Val g-mean: None\nEpoch: 109, Train loss: 0.3650897180879736, Train g-mean: 0.8516345683276029, Val g-mean: None\nEpoch: 110, Train loss: 0.3609100148749756, Train g-mean: 0.8504631110558055, Val g-mean: None\nEpoch: 111, Train loss: 0.3662674105477346, Train g-mean: 0.8502948738077037, Val g-mean: None\nEpoch: 112, Train loss: 0.35937244942211344, Train g-mean: 0.8506082328880674, Val g-mean: None\nEpoch: 113, Train loss: 0.36056673086151747, Train g-mean: 0.8518840685794367, Val g-mean: None\nEpoch: 114, Train loss: 0.35892193053245075, Train g-mean: 0.851144378072433, Val g-mean: None\nEpoch: 115, Train loss: 0.36009939304413313, Train g-mean: 0.8507958351729928, Val g-mean: None\nEpoch: 116, Train loss: 0.3586821177285916, Train g-mean: 0.8516185222424554, Val g-mean: None\nEpoch: 117, Train loss: 0.3531555550030547, Train g-mean: 0.8510333850319854, Val g-mean: None\nEpoch: 118, Train loss: 0.36337637810531376, Train g-mean: 0.8510759530700589, Val g-mean: None\nEpoch: 119, Train loss: 0.3675733631364194, Train g-mean: 0.8500261947419144, Val g-mean: None\nEpoch: 120, Train loss: 0.36243084786243235, Train g-mean: 0.8496365470803929, Val g-mean: None\nEpoch: 121, Train loss: 0.36558660695562667, Train g-mean: 0.8505264427494938, Val g-mean: None\nEpoch: 122, Train loss: 0.3603911591568333, Train g-mean: 0.8500602340796152, Val g-mean: None\nEpoch: 123, Train loss: 0.3574195731487285, Train g-mean: 0.8508370819876062, Val g-mean: None\nEpoch: 124, Train loss: 0.36566923487829395, Train g-mean: 0.850345587279035, Val g-mean: None\nEpoch: 125, Train loss: 0.35474698339375343, Train g-mean: 0.8504813147063246, Val g-mean: None\nEpoch: 126, Train loss: 0.362672791876611, Train g-mean: 0.8510944007716311, Val g-mean: None\nEpoch: 127, Train loss: 0.3555417219797199, Train g-mean: 0.8509535224626823, Val g-mean: None\nEpoch: 128, Train loss: 0.36090893854376904, Train g-mean: 0.8520694882744185, Val g-mean: None\nEpoch: 129, Train loss: 0.35768086048533754, Train g-mean: 0.8514140585522801, Val g-mean: None\nEpoch: 130, Train loss: 0.36005518523998487, Train g-mean: 0.8511347515090611, Val g-mean: None\nEpoch: 131, Train loss: 0.3661150915289911, Train g-mean: 0.8511262555093243, Val g-mean: None\nEpoch: 132, Train loss: 0.36540466733794374, Train g-mean: 0.8503633871287231, Val g-mean: None\nEpoch: 133, Train loss: 0.37245909250808695, Train g-mean: 0.8506433271568974, Val g-mean: None\nEpoch: 134, Train loss: 0.3628810771937758, Train g-mean: 0.8499183690668499, Val g-mean: None\nEpoch: 135, Train loss: 0.36296319906633256, Train g-mean: 0.8501476315242845, Val g-mean: None\nEpoch: 136, Train loss: 0.3606839564361627, Train g-mean: 0.8500136805705961, Val g-mean: None\nEpoch: 137, Train loss: 0.3600005606391047, Train g-mean: 0.8506501240782162, Val g-mean: None\nEpoch: 138, Train loss: 0.3640564750586082, Train g-mean: 0.8504662909862135, Val g-mean: None\nEpoch: 139, Train loss: 0.3476399608547781, Train g-mean: 0.8512989294801436, Val g-mean: None\nEpoch: 140, Train loss: 0.35956601214695777, Train g-mean: 0.8512840538256112, Val g-mean: None\nEpoch: 141, Train loss: 0.356385312065094, Train g-mean: 0.8513810072294862, Val g-mean: None\nEpoch: 142, Train loss: 0.36105328771326517, Train g-mean: 0.8511007942042824, Val g-mean: None\nEpoch: 143, Train loss: 0.3516348110004309, Train g-mean: 0.8510346279798674, Val g-mean: None\nEpoch: 144, Train loss: 0.3545157999324672, Train g-mean: 0.8510924369655678, Val g-mean: None\nEpoch: 145, Train loss: 0.36555678835007416, Train g-mean: 0.8504561064088051, Val g-mean: None\nEpoch: 146, Train loss: 0.3605748966786467, Train g-mean: 0.8509999876421114, Val g-mean: None\nEpoch: 147, Train loss: 0.3581041076986161, Train g-mean: 0.850957878362115, Val g-mean: None\nEpoch: 148, Train loss: 0.35814482639940887, Train g-mean: 0.851133897828124, Val g-mean: None\nEpoch: 149, Train loss: 0.3695449437091146, Train g-mean: 0.8509267590714207, Val g-mean: None\nEpoch: 150, Train loss: 0.34993421616538045, Train g-mean: 0.8499686690144297, Val g-mean: None\nEpoch: 151, Train loss: 0.36579294152874575, Train g-mean: 0.8505551475359011, Val g-mean: None\nEpoch: 152, Train loss: 0.3510984791696132, Train g-mean: 0.8508381960677541, Val g-mean: None\nEpoch: 153, Train loss: 0.3593972210389954, Train g-mean: 0.8509962759134405, Val g-mean: None\nEpoch: 154, Train loss: 0.3613826205791408, Train g-mean: 0.8516982039388586, Val g-mean: None\nEpoch: 155, Train loss: 0.35722207885423457, Train g-mean: 0.8515999530544528, Val g-mean: None\nEpoch: 156, Train loss: 0.3575942112109479, Train g-mean: 0.8516642294276682, Val g-mean: None\nEpoch: 157, Train loss: 0.3576264541415163, Train g-mean: 0.8510233236758686, Val g-mean: None\nEpoch: 158, Train loss: 0.36484962368866386, Train g-mean: 0.8511149733387081, Val g-mean: None\nEpoch: 159, Train loss: 0.3568844486516203, Train g-mean: 0.8507154027068633, Val g-mean: None\nEpoch: 160, Train loss: 0.35691541910569347, Train g-mean: 0.8504617686117082, Val g-mean: None\nEpoch: 161, Train loss: 0.3753069111994519, Train g-mean: 0.8508352526219256, Val g-mean: None\nEpoch: 162, Train loss: 0.35429638646396133, Train g-mean: 0.8506301471254079, Val g-mean: None\nEpoch: 163, Train loss: 0.3582831544332453, Train g-mean: 0.8514827951624574, Val g-mean: None\nEpoch: 164, Train loss: 0.3545393133761189, Train g-mean: 0.8507188521985456, Val g-mean: None\nEpoch: 165, Train loss: 0.36626161710101335, Train g-mean: 0.8511605199307511, Val g-mean: None\nEpoch: 166, Train loss: 0.35895646534160836, Train g-mean: 0.8507973318911122, Val g-mean: None\nEpoch: 167, Train loss: 0.3572020418290797, Train g-mean: 0.8514704417435184, Val g-mean: None\nEpoch: 168, Train loss: 0.3592316139348236, Train g-mean: 0.8515337399097158, Val g-mean: None\nEpoch: 169, Train loss: 0.35906976342396035, Train g-mean: 0.8514240841400149, Val g-mean: None\nEpoch: 170, Train loss: 0.3570577059638744, Train g-mean: 0.8507092113139811, Val g-mean: None\nEpoch: 171, Train loss: 0.35543119283918495, Train g-mean: 0.8509638648927287, Val g-mean: None\nEpoch: 172, Train loss: 0.3631433400327172, Train g-mean: 0.8510171820154374, Val g-mean: None\nEpoch: 173, Train loss: 0.3593344837517322, Train g-mean: 0.8515657582724293, Val g-mean: None\nEpoch: 174, Train loss: 0.35939359040058677, Train g-mean: 0.8522500135068554, Val g-mean: None\nEpoch: 175, Train loss: 0.3625220894720596, Train g-mean: 0.8513658382367244, Val g-mean: None\nEpoch: 176, Train loss: 0.3620501860492538, Train g-mean: 0.8515056738758098, Val g-mean: None\nEpoch: 177, Train loss: 0.3579410260227198, Train g-mean: 0.851884049519893, Val g-mean: None\nEpoch: 178, Train loss: 0.35474429574482824, Train g-mean: 0.851643551399166, Val g-mean: None\nEpoch: 179, Train loss: 0.3603104481283289, Train g-mean: 0.8508318431193245, Val g-mean: None\nEpoch: 180, Train loss: 0.348632663902363, Train g-mean: 0.8511988521692905, Val g-mean: None\nEpoch: 181, Train loss: 0.3590032910280561, Train g-mean: 0.8519948607449419, Val g-mean: None\nEpoch: 182, Train loss: 0.3582333033282691, Train g-mean: 0.851734075241077, Val g-mean: None\nEpoch: 183, Train loss: 0.3565544765001956, Train g-mean: 0.8520225601593857, Val g-mean: None\nEpoch: 184, Train loss: 0.3598452719334839, Train g-mean: 0.8516457520189505, Val g-mean: None\nEpoch: 185, Train loss: 0.3631470181361452, Train g-mean: 0.8512496615056284, Val g-mean: None\nEpoch: 186, Train loss: 0.36238178315283026, Train g-mean: 0.8507979173324, Val g-mean: None\nEpoch: 187, Train loss: 0.36025412899913367, Train g-mean: 0.850343105773001, Val g-mean: None\nEpoch: 188, Train loss: 0.3574128868831941, Train g-mean: 0.8505928633909834, Val g-mean: None\nEpoch: 189, Train loss: 0.34859841332209285, Train g-mean: 0.850454054438453, Val g-mean: None\nEpoch: 190, Train loss: 0.3682097549929966, Train g-mean: 0.8510056579868104, Val g-mean: None\nEpoch: 191, Train loss: 0.35206907332486603, Train g-mean: 0.8510106382075131, Val g-mean: None\nEpoch: 192, Train loss: 0.36486122087142375, Train g-mean: 0.8512941046388941, Val g-mean: None\nEpoch: 193, Train loss: 0.35877782204955544, Train g-mean: 0.8514094179143163, Val g-mean: None\nEpoch: 194, Train loss: 0.35353188748616354, Train g-mean: 0.8517665660096747, Val g-mean: None\nEpoch: 195, Train loss: 0.3575865680926136, Train g-mean: 0.8504779454624938, Val g-mean: None\nEpoch: 196, Train loss: 0.3589663209291975, Train g-mean: 0.8509574847168822, Val g-mean: None\nEpoch: 197, Train loss: 0.36430847068554834, Train g-mean: 0.8505007308440724, Val g-mean: None\nEpoch: 198, Train loss: 0.3585121014489688, Train g-mean: 0.8506047711420264, Val g-mean: None\nEpoch: 199, Train loss: 0.3671151495068751, Train g-mean: 0.850500520372923, Val g-mean: None\n"
        }
      ],
      "source": [
        "pipeline = Pipeline(steps=[], classifier=classifier, optimizer=optimizer, criterion=criterion, max_epochs=200, fading_factor=0.9999)\n",
        "pipeline.train(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [],
      "source": [
        "  def evaluate(pipeline):\n",
        "    train_gmean, train_recalls = pipeline.evaluate(X_train, y_train)\n",
        "    test_gmean, test_recalls = pipeline.evaluate(X_test, y_test)\n",
        "    print('Epoch: {}'.format(pipeline.epoch))\n",
        "    print('Train g-mean: {}, recalls: {}'.format(train_gmean.item(), train_recalls))\n",
        "    print('Test g-mean: {}, recalls: {}'.format(test_gmean.item(), test_recalls))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Last classifier\nEpoch: 199\nTrain g-mean: 0.850500520372923, recalls: [0.74331318 0.9731445 ]\nTest g-mean: 0.647925287847743, recalls: [0.49340125 0.85084336]\n"
        }
      ],
      "source": [
        "print('Last classifier')\n",
        "evaluate(pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [],
      "source": [
        "if pipeline.has_validation():\n",
        "    print('Best classifier')\n",
        "    pipeline.load()\n",
        "    evaluate(pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "L_t4Gh43GYWl"
      },
      "outputs": [],
      "source": []
    }
  ]
}