{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JIT-SDP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dinaldoap/jit-sdp-nn/blob/master/notebook/mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "/workspace\n"
        }
      ],
      "source": [
        "%cd /workspace/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import random\n",
        "from scipy.stats import mstats\n",
        "import math\n",
        "import re\n",
        "\n",
        "from jitsdp import metrics\n",
        "from jitsdp.classifier import Classifier\n",
        "from jitsdp.pipeline import Pipeline\n",
        "\n",
        "import logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "logging.getLogger('').handlers = []\n",
        "logging.basicConfig(filename='notebook/mlp.log', filemode='w', level=logging.DEBUG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>commit_hash</th>\n      <th>author_name</th>\n      <th>author_date_unix_timestamp</th>\n      <th>author_email</th>\n      <th>author_date</th>\n      <th>commit_message</th>\n      <th>fix</th>\n      <th>classification</th>\n      <th>linked</th>\n      <th>contains_bug</th>\n      <th>...</th>\n      <th>nuc</th>\n      <th>exp</th>\n      <th>rexp</th>\n      <th>sexp</th>\n      <th>glm_probability</th>\n      <th>rf_probability</th>\n      <th>repository_id</th>\n      <th>issue_id</th>\n      <th>issue_date</th>\n      <th>issue_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>5f406086936d2abf1392b0f77db246b308715d6d</td>\n      <td>Narayani</td>\n      <td>1574927837</td>\n      <td>narayani@adobe.com</td>\n      <td>Thu Nov 28 13:27:17 2019 +0530</td>\n      <td>Merge pull request #14985 from adobe/alf_local...</td>\n      <td>NaN</td>\n      <td>Merge</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.173803</td>\n      <td>0.000</td>\n      <td>3dc71fdd-a705-47f1-9685-0dbc873af923</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>95626cc3650dcd00e886670d80307b8f710d6168</td>\n      <td>walf</td>\n      <td>1574926230</td>\n      <td>walf@adobe.com</td>\n      <td>Wed Nov 27 23:30:30 2019 -0800</td>\n      <td>Updated by ALF automation.</td>\n      <td>False</td>\n      <td>None</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>9.0</td>\n      <td>1.075033</td>\n      <td>8.0</td>\n      <td>0.464372</td>\n      <td>0.286</td>\n      <td>3dc71fdd-a705-47f1-9685-0dbc873af923</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>8f26cd850e648d6c4dd04cdfa69119a7feda0867</td>\n      <td>walf</td>\n      <td>1574915324</td>\n      <td>walf@adobe.com</td>\n      <td>Wed Nov 27 20:28:44 2019 -0800</td>\n      <td>Updated by ALF automation.</td>\n      <td>False</td>\n      <td>None</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>8.0</td>\n      <td>0.075033</td>\n      <td>7.0</td>\n      <td>0.459778</td>\n      <td>0.302</td>\n      <td>3dc71fdd-a705-47f1-9685-0dbc873af923</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>a7dda4aeab550d36bc2c0ca4ecfc29efda21f9ea</td>\n      <td>Narayani</td>\n      <td>1574757872</td>\n      <td>narayani@adobe.com</td>\n      <td>Tue Nov 26 14:14:32 2019 +0530</td>\n      <td>Merge pull request #14729 from adobe/alf_local...</td>\n      <td>NaN</td>\n      <td>Merge</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.173803</td>\n      <td>0.000</td>\n      <td>3dc71fdd-a705-47f1-9685-0dbc873af923</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>8a806ec41b613d70b26005e2c4907b021a41e744</td>\n      <td>Gautam Jha</td>\n      <td>1574315174</td>\n      <td>gjha@adobe.com</td>\n      <td>Thu Nov 21 11:16:14 2019 +0530</td>\n      <td>Moving command line port validation errors to ...</td>\n      <td>False</td>\n      <td>None</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>2.500000</td>\n      <td>2.0</td>\n      <td>0.640227</td>\n      <td>0.496</td>\n      <td>3dc71fdd-a705-47f1-9685-0dbc873af923</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 31 columns</p>\n</div>",
            "text/plain": "                                commit_hash author_name  \\\n0  5f406086936d2abf1392b0f77db246b308715d6d    Narayani   \n1  95626cc3650dcd00e886670d80307b8f710d6168        walf   \n2  8f26cd850e648d6c4dd04cdfa69119a7feda0867        walf   \n3  a7dda4aeab550d36bc2c0ca4ecfc29efda21f9ea    Narayani   \n4  8a806ec41b613d70b26005e2c4907b021a41e744  Gautam Jha   \n\n   author_date_unix_timestamp        author_email  \\\n0                  1574927837  narayani@adobe.com   \n1                  1574926230      walf@adobe.com   \n2                  1574915324      walf@adobe.com   \n3                  1574757872  narayani@adobe.com   \n4                  1574315174      gjha@adobe.com   \n\n                      author_date  \\\n0  Thu Nov 28 13:27:17 2019 +0530   \n1  Wed Nov 27 23:30:30 2019 -0800   \n2  Wed Nov 27 20:28:44 2019 -0800   \n3  Tue Nov 26 14:14:32 2019 +0530   \n4  Thu Nov 21 11:16:14 2019 +0530   \n\n                                      commit_message    fix classification  \\\n0  Merge pull request #14985 from adobe/alf_local...    NaN          Merge   \n1                        Updated by ALF automation.   False           None   \n2                        Updated by ALF automation.   False           None   \n3  Merge pull request #14729 from adobe/alf_local...    NaN          Merge   \n4  Moving command line port validation errors to ...  False           None   \n\n   linked  contains_bug  ...  nuc  exp      rexp  sexp  glm_probability  \\\n0   False         False  ...  0.0  0.0  0.000000   0.0         0.173803   \n1   False         False  ...  1.0  9.0  1.075033   8.0         0.464372   \n2   False         False  ...  1.0  8.0  0.075033   7.0         0.459778   \n3   False         False  ...  0.0  0.0  0.000000   0.0         0.173803   \n4   False         False  ...  2.0  4.0  2.500000   2.0         0.640227   \n\n   rf_probability                         repository_id issue_id  issue_date  \\\n0           0.000  3dc71fdd-a705-47f1-9685-0dbc873af923      NaN         NaN   \n1           0.286  3dc71fdd-a705-47f1-9685-0dbc873af923      NaN         NaN   \n2           0.302  3dc71fdd-a705-47f1-9685-0dbc873af923      NaN         NaN   \n3           0.000  3dc71fdd-a705-47f1-9685-0dbc873af923      NaN         NaN   \n4           0.496  3dc71fdd-a705-47f1-9685-0dbc873af923      NaN         NaN   \n\n   issue_type  \n0         NaN  \n1         NaN  \n2         NaN  \n3         NaN  \n4         NaN  \n\n[5 rows x 31 columns]"
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/dinaldoap/jit-sdp-data/master/brackets.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>commit_hash</th>\n      <th>author_date_unix_timestamp</th>\n      <th>fixes</th>\n      <th>fix</th>\n      <th>ns</th>\n      <th>nd</th>\n      <th>nf</th>\n      <th>entropy</th>\n      <th>la</th>\n      <th>ld</th>\n      <th>...</th>\n      <th>nuc</th>\n      <th>exp</th>\n      <th>rexp</th>\n      <th>sexp</th>\n      <th>contains_bug</th>\n      <th>seq</th>\n      <th>day</th>\n      <th>commit_hash_fix</th>\n      <th>day_fix</th>\n      <th>seq_fix</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>17747</td>\n      <td>637d7f4ffa0f2396c2fb61a5e51b9b980f47a2c2</td>\n      <td>1323292816</td>\n      <td>[\"c94ebc139b7ca8ae681c71d28e051f4270d493c4\", \"...</td>\n      <td>False</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>23.0</td>\n      <td>3.630787</td>\n      <td>3754.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>c94ebc139b7ca8ae681c71d28e051f4270d493c4</td>\n      <td>30.0</td>\n      <td>206.0</td>\n    </tr>\n    <tr>\n      <td>17746</td>\n      <td>c8142d2dc17fc1d3777689d67d32d010f5d8dfa7</td>\n      <td>1323292845</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.811278</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <td>17745</td>\n      <td>af90ea5adf06c935ce1d5db4ce996054c94aeed7</td>\n      <td>1323294546</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <td>17744</td>\n      <td>82f3f98077bde9ac7c4ff285c593a2f351da5bf2</td>\n      <td>1323295924</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <td>17743</td>\n      <td>a454a7bce095b18da240cddf844bfea5a334b7cb</td>\n      <td>1323301755</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 23 columns</p>\n</div>",
            "text/plain": "                                    commit_hash  author_date_unix_timestamp  \\\n17747  637d7f4ffa0f2396c2fb61a5e51b9b980f47a2c2                  1323292816   \n17746  c8142d2dc17fc1d3777689d67d32d010f5d8dfa7                  1323292845   \n17745  af90ea5adf06c935ce1d5db4ce996054c94aeed7                  1323294546   \n17744  82f3f98077bde9ac7c4ff285c593a2f351da5bf2                  1323295924   \n17743  a454a7bce095b18da240cddf844bfea5a334b7cb                  1323301755   \n\n                                                   fixes    fix   ns   nd  \\\n17747  [\"c94ebc139b7ca8ae681c71d28e051f4270d493c4\", \"...  False  2.0  5.0   \n17746                                                NaN  False  2.0  2.0   \n17745                                                NaN   True  1.0  1.0   \n17744                                                NaN  False  1.0  1.0   \n17743                                                NaN  False  1.0  1.0   \n\n         nf   entropy      la   ld  ...  nuc  exp  rexp  sexp  contains_bug  \\\n17747  23.0  3.630787  3754.0  0.0  ...  0.0  0.0   0.0   0.0             1   \n17746   2.0  0.811278     4.0  0.0  ...  0.0  1.0   1.0   0.0             0   \n17745   1.0  0.000000     1.0  1.0  ...  1.0  2.0   2.0   1.0             0   \n17744   1.0  0.000000     2.0  3.0  ...  1.0  3.0   3.0   2.0             0   \n17743   1.0  0.000000     5.0  0.0  ...  0.0  0.0   0.0   0.0             0   \n\n       seq  day                           commit_hash_fix  day_fix  seq_fix  \n17747    0    0  c94ebc139b7ca8ae681c71d28e051f4270d493c4     30.0    206.0  \n17746    1    0                                       NaN      NaN      NaN  \n17745    2    0                                       NaN      NaN      NaN  \n17744    3    0                                       NaN      NaN      NaN  \n17743    4    0                                       NaN      NaN      NaN  \n\n[5 rows x 23 columns]"
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_col = 'contains_bug'\n",
        "features_cols = ['fix', 'ns', 'nd', 'nf', 'entropy', 'la', 'ld', 'lt', 'ndev', 'age', 'nuc', 'exp', 'rexp', 'sexp']\n",
        "preprocess_cols = ['commit_hash', 'author_date_unix_timestamp', 'fixes'] + features_cols + [label_col]\n",
        "seconds_by_day = 24 * 60 * 60\n",
        "df_preprocess = df[preprocess_cols].copy()\n",
        "# filter rows with missing data \n",
        "df_preprocess = df_preprocess.dropna(subset=['fix'])\n",
        "# timeline order\n",
        "df_preprocess = df_preprocess[::-1]\n",
        "# add sequencial\n",
        "df_preprocess['seq'] = range(len(df_preprocess))\n",
        "# contains_bug\n",
        "df_preprocess[label_col] = df_preprocess[label_col].astype('int')\n",
        "# day\n",
        "first_timestamp = df_preprocess['author_date_unix_timestamp'].min()\n",
        "df_preprocess['day'] = df_preprocess['author_date_unix_timestamp'] - first_timestamp\n",
        "df_preprocess['day'] = df_preprocess['day'] / seconds_by_day\n",
        "df_preprocess['day'] = df_preprocess['day'].astype('int')\n",
        "# fixes\n",
        "df_preprocess['commit_hash_fix'] = df_preprocess['fixes'].dropna().apply(lambda x: re.findall('\\\\b\\\\w+\\\\b', x)[0])\n",
        "df_fix = df_preprocess[['commit_hash', 'day', 'seq']].set_index('commit_hash')\n",
        "df_preprocess = df_preprocess.join(df_fix, on='commit_hash_fix', how='left', rsuffix='_fix')\n",
        "df_preprocess.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "prequential_cols = ['day', 'day_fix', 'seq', 'seq_fix'] + features_cols + [label_col]\n",
        "# TODO: exclude last commits which aren't labeled\n",
        "df_prequential = df_preprocess[prequential_cols].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_pipeline():\n",
        "    scaler = StandardScaler()\n",
        "    criterion = nn.BCELoss()\n",
        "    classifier = Classifier(input_size=len(features_cols), hidden_size=len(features_cols) // 2, drop_prob=0.2)\n",
        "    optimizer = optim.Adam(params=classifier.parameters(), lr=0.003)\n",
        "    return Pipeline(steps=[scaler], classifier=classifier, optimizer=optimizer, criterion=criterion, max_epochs=200, fading_factor=0.9999)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "  def evaluate(label, targets, predictions):\n",
        "    gmean, recalls = metrics.gmean_recalls(targets, predictions)\n",
        "    print('{} g-mean: {}, recalls: {}'.format(label, gmean, recalls))\n",
        "  \n",
        "  def evaluate_train_test(seq, targets_train, predictions_train, targets_test, predictions_test):\n",
        "    print('Sequential: {}'.format(seq))\n",
        "    evaluate('Train', targets_train, predictions_train)\n",
        "    evaluate('Test', targets_test, predictions_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "/home/pytorch/.conda/envs/pytorch/lib/python3.7/site-packages/scipy/stats/stats.py:338: RuntimeWarning: divide by zero encountered in log\n  log_a = np.log(a)\nSequential: 500\nTrain g-mean: 0.7647433124908976, recalls: [0.66959064 0.87341772]\nTest g-mean: 0.5896431189332371, recalls: [0.87859425 0.39572193]\nSequential: 1000\nTrain g-mean: 0.7974602923010693, recalls: [0.72374101 0.87868852]\nTest g-mean: 0.4340104415468487, recalls: [0.88073394 0.21387283]\nSequential: 1500\nTrain g-mean: 0.7793655496628967, recalls: [0.70038168 0.86725664]\nTest g-mean: 0.6789209971474433, recalls: [0.81446541 0.56593407]\nSequential: 2000\nTrain g-mean: 0.7738833968508804, recalls: [0.69927536 0.85645161]\nTest g-mean: 0.7042936143247844, recalls: [0.80487805 0.61627907]\nSequential: 2500\nTrain g-mean: 0.7702149126033707, recalls: [0.72819358 0.81466113]\nTest g-mean: 0.7335104362592145, recalls: [0.85478548 0.62944162]\nSequential: 3000\nTrain g-mean: 0.7677478577692306, recalls: [0.74964706 0.78628571]\nTest g-mean: 0.684918206837917, recalls: [0.81845238 0.57317073]\nSequential: 3500\nTrain g-mean: 0.7669667043067473, recalls: [0.76530199 0.76863504]\nTest g-mean: 0.6660808211774806, recalls: [0.82991202 0.53459119]\nSequential: 4000\nTrain g-mean: 0.7592490801423147, recalls: [0.73030518 0.7893401 ]\nTest g-mean: 0.6870847006581398, recalls: [0.79310345 0.5952381 ]\nSequential: 4500\nTrain g-mean: 0.7612739802126639, recalls: [0.75920051 0.76335312]\nTest g-mean: 0.6509950331373728, recalls: [0.75568182 0.56081081]\nSequential: 5000\nTrain g-mean: 0.7510204367774015, recalls: [0.76023891 0.74191375]\nTest g-mean: 0.6978724440066307, recalls: [0.73273273 0.66467066]\nSequential: 5500\nTrain g-mean: 0.7445031986711063, recalls: [0.70206644 0.78950507]\nTest g-mean: 0.7586799520622175, recalls: [0.74311927 0.77456647]\nSequential: 6000\nTrain g-mean: 0.7437246552732996, recalls: [0.74933269 0.73815859]\nTest g-mean: 0.6994503336411839, recalls: [0.81538462 0.6       ]\nSequential: 6500\nTrain g-mean: 0.7418667034299953, recalls: [0.73906319 0.74468085]\nTest g-mean: 0.7201190377787714, recalls: [0.78571429 0.66      ]\nSequential: 7000\nTrain g-mean: 0.7439049080139764, recalls: [0.73809524 0.74976031]\nTest g-mean: 0.7384091089068558, recalls: [0.79778393 0.68345324]\nSequential: 7500\nTrain g-mean: 0.7440683543888225, recalls: [0.73654175 0.75167187]\nTest g-mean: 0.716350399411375, recalls: [0.82105263 0.625     ]\nSequential: 8000\nTrain g-mean: 0.739510331642671, recalls: [0.72720836 0.75202042]\nTest g-mean: 0.718981255907138, recalls: [0.77540107 0.66666667]\nSequential: 8500\nTrain g-mean: 0.7385442606979273, recalls: [0.73865154 0.738437  ]\nTest g-mean: 0.7186967371569135, recalls: [0.7275 0.71  ]\nSequential: 9000\nTrain g-mean: 0.737242488957922, recalls: [0.68931886 0.78849792]\nTest g-mean: 0.6497099474942729, recalls: [0.66071429 0.63888889]\nSequential: 9500\nTrain g-mean: 0.7381137835684017, recalls: [0.71526027 0.7616975 ]\nTest g-mean: 0.6622616352900803, recalls: [0.70801034 0.61946903]\nSequential: 10000\nTrain g-mean: 0.7416907647986518, recalls: [0.71211908 0.77249045]\nTest g-mean: 0.6750220398559319, recalls: [0.72456576 0.62886598]\nSequential: 10500\nTrain g-mean: 0.7380886138896123, recalls: [0.71248829 0.76460878]\nTest g-mean: 0.7251835842111002, recalls: [0.74603175 0.70491803]\nSequential: 11000\nTrain g-mean: 0.7401191854099158, recalls: [0.72390443 0.75669713]\nTest g-mean: 0.7011766588360926, recalls: [0.76041667 0.64655172]\nSequential: 11500\nTrain g-mean: 0.7419849726740053, recalls: [0.71090396 0.77442486]\nTest g-mean: 0.6722708174151582, recalls: [0.77333333 0.58441558]\nFull test g-mean: 0.6815952778346646, recalls: [0.77978384 0.59577039]\n"
        }
      ],
      "source": [
        "# split dataset in chunks for testing and iterate over them (chunk from current to current + interval or end)\n",
        "# the previous chunks are used for training (chunks from start to current)\n",
        "verification_latency = 0 # days\n",
        "interval = 500 # commits\n",
        "end = len(df_prequential) # last commit\n",
        "n_chunks = math.ceil(end / interval)\n",
        "end = n_chunks * interval # last chunk end\n",
        "start = end - (n_chunks - 1) * interval # second chunk start\n",
        "#start = end - interval # last chunk start\n",
        "\n",
        "pipeline = create_pipeline()\n",
        "pipeline.save()\n",
        "predictions = []\n",
        "for current in range(start, end, interval):\n",
        "#for current in range(start, start+1, interval):\n",
        "    df_train = df_prequential[:current].copy()\n",
        "    df_test = df_prequential[current:min(current + interval, end)].copy()\n",
        "    # check if fix has been done (bug) or verification latency has passed (normal), otherwise exclude commit\n",
        "    train_day = df_train['day'].max()\n",
        "    train_seq = df_train['seq'].max()\n",
        "    df_train[label_col] = df_train.apply(lambda row: 1 if row.seq_fix <= train_seq else (0 if row.day <= train_day - verification_latency else None), axis='columns')\n",
        "    df_train = df_train.dropna(subset=[label_col])\n",
        "    df_train[label_col] = df_train[label_col].astype('int')\n",
        "    # convert to numpy array\n",
        "    X_train = df_train[features_cols].values\n",
        "    y_train = df_train[label_col].values\n",
        "    X_test = df_test[features_cols].values\n",
        "    y_test = df_test[label_col].values\n",
        "    # train and evaluate\n",
        "    pipeline = create_pipeline()\n",
        "    pipeline.load()\n",
        "    pipeline.train(X_train, y_train)\n",
        "    pipeline.save()\n",
        "    predictions_test = pipeline.predict(X_test)    \n",
        "    evaluate_train_test(current, y_train, pipeline.predict(X_train), y_test, predictions_test)\n",
        "    predictions.append(predictions_test)\n",
        "\n",
        "predictions = np.concatenate(predictions)\n",
        "targets = df_prequential[label_col][start:].values\n",
        "evaluate('Full test', targets, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "L_t4Gh43GYWl"
      },
      "outputs": [],
      "source": []
    }
  ]
}