{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JIT-SDP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python37064bite406851a25184002a8fe65dca1936b2d",
      "display_name": "Python 3.7.0 64-bit"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dinaldoap/jit-sdp-nn/blob/master/notebook/mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "/workspace\n"
        }
      ],
      "source": [
        "%cd /workspace/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import random\n",
        "from scipy.stats import mstats\n",
        "import math\n",
        "import re\n",
        "\n",
        "from jitsdp import metrics\n",
        "from jitsdp.classifier import Classifier\n",
        "from jitsdp.pipeline import Pipeline\n",
        "\n",
        "import logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {},
      "outputs": [],
      "source": [
        "logging.getLogger('').handlers = []\n",
        "logging.basicConfig(filename='notebook/mlp.log', filemode='w', level=logging.DEBUG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>commit_hash</th>\n      <th>author_name</th>\n      <th>author_date_unix_timestamp</th>\n      <th>author_email</th>\n      <th>author_date</th>\n      <th>commit_message</th>\n      <th>fix</th>\n      <th>classification</th>\n      <th>linked</th>\n      <th>contains_bug</th>\n      <th>...</th>\n      <th>fileschanged</th>\n      <th>lt</th>\n      <th>ndev</th>\n      <th>age</th>\n      <th>nuc</th>\n      <th>exp</th>\n      <th>rexp</th>\n      <th>sexp</th>\n      <th>glm_probability</th>\n      <th>repository_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>b96625a4b8e0aaaf58ca56082ed29dbc588e9379</td>\n      <td>ficristo</td>\n      <td>1512664331</td>\n      <td>ficristo.work@gmail.com</td>\n      <td>Thu Dec 7 17:32:11 2017 +0100</td>\n      <td>Remove PanelManager (#11589)</td>\n      <td>False</td>\n      <td>None</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>src/brackets.js,CAS_DELIMITER,src/search/Searc...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.450896</td>\n      <td>62af12f4-9856-421d-a18b-16a4d7b39c63</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>51417390f9b7aedf983f0f847d578dd819765c6d</td>\n      <td>ficristo</td>\n      <td>1512664256</td>\n      <td>ficristo.work@gmail.com</td>\n      <td>Thu Dec 7 17:30:56 2017 +0100</td>\n      <td>Add wrapper functions to call the fs-extra one...</td>\n      <td>False</td>\n      <td>Feature Addition</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>test/node/TestingDomain.js,CAS_DELIMITER</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.401964</td>\n      <td>62af12f4-9856-421d-a18b-16a4d7b39c63</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>13af302a2a5bbbe459fa7ac060203dd410de97e9</td>\n      <td>Naveen Choudhary</td>\n      <td>1512657100</td>\n      <td>navch@users.noreply.github.com</td>\n      <td>Thu Dec 7 20:01:40 2017 +0530</td>\n      <td>Merge pull request #13945 from JungGaBin/fixtt...</td>\n      <td>False</td>\n      <td>Merge</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.201657</td>\n      <td>62af12f4-9856-421d-a18b-16a4d7b39c63</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>63e07fd375fcf6a29fe37b566464d4591f8f0b69</td>\n      <td>Prashanth Nethi</td>\n      <td>1512448426</td>\n      <td>prashant@adobe.com</td>\n      <td>Tue Dec 5 10:03:46 2017 +0530</td>\n      <td>Merge pull request #13852 from toryherman/1377...</td>\n      <td>False</td>\n      <td>Merge</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.201657</td>\n      <td>62af12f4-9856-421d-a18b-16a4d7b39c63</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>cf8dc16872045735ba485a90eec104b5517a909a</td>\n      <td>JungGaBin</td>\n      <td>1511896569</td>\n      <td>jgb5131@naver.com</td>\n      <td>Wed Nov 29 04:16:09 2017 +0900</td>\n      <td>Correct typo (#13938)Inpsector -&gt; Inspector</td>\n      <td>False</td>\n      <td>None</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>test/spec/LiveDevelopment-test.js,CAS_DELIMITER</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.402032</td>\n      <td>62af12f4-9856-421d-a18b-16a4d7b39c63</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 27 columns</p>\n</div>",
            "text/plain": "                                commit_hash       author_name  \\\n0  b96625a4b8e0aaaf58ca56082ed29dbc588e9379          ficristo   \n1  51417390f9b7aedf983f0f847d578dd819765c6d          ficristo   \n2  13af302a2a5bbbe459fa7ac060203dd410de97e9  Naveen Choudhary   \n3  63e07fd375fcf6a29fe37b566464d4591f8f0b69   Prashanth Nethi   \n4  cf8dc16872045735ba485a90eec104b5517a909a         JungGaBin   \n\n   author_date_unix_timestamp                    author_email  \\\n0                  1512664331         ficristo.work@gmail.com   \n1                  1512664256         ficristo.work@gmail.com   \n2                  1512657100  navch@users.noreply.github.com   \n3                  1512448426              prashant@adobe.com   \n4                  1511896569               jgb5131@naver.com   \n\n                      author_date  \\\n0   Thu Dec 7 17:32:11 2017 +0100   \n1   Thu Dec 7 17:30:56 2017 +0100   \n2   Thu Dec 7 20:01:40 2017 +0530   \n3   Tue Dec 5 10:03:46 2017 +0530   \n4  Wed Nov 29 04:16:09 2017 +0900   \n\n                                      commit_message    fix    classification  \\\n0                       Remove PanelManager (#11589)  False              None   \n1  Add wrapper functions to call the fs-extra one...  False  Feature Addition   \n2  Merge pull request #13945 from JungGaBin/fixtt...  False             Merge   \n3  Merge pull request #13852 from toryherman/1377...  False             Merge   \n4        Correct typo (#13938)Inpsector -> Inspector  False              None   \n\n   linked  contains_bug  ...  \\\n0   False         False  ...   \n1   False         False  ...   \n2   False         False  ...   \n3   False         False  ...   \n4   False         False  ...   \n\n                                        fileschanged   lt  ndev  age  nuc  \\\n0  src/brackets.js,CAS_DELIMITER,src/search/Searc...  0.0   1.0  0.0  0.0   \n1           test/node/TestingDomain.js,CAS_DELIMITER  0.0   1.0  0.0  0.0   \n2                                                NaN  0.0   0.0  0.0  0.0   \n3                                                NaN  0.0   0.0  0.0  0.0   \n4    test/spec/LiveDevelopment-test.js,CAS_DELIMITER  0.0   1.0  0.0  0.0   \n\n   exp  rexp sexp  glm_probability                         repository_id  \n0  2.0   0.0  2.0         0.450896  62af12f4-9856-421d-a18b-16a4d7b39c63  \n1  0.0   0.0  0.0         0.401964  62af12f4-9856-421d-a18b-16a4d7b39c63  \n2  0.0   0.0  0.0         0.201657  62af12f4-9856-421d-a18b-16a4d7b39c63  \n3  0.0   0.0  0.0         0.201657  62af12f4-9856-421d-a18b-16a4d7b39c63  \n4  3.0   0.0  1.0         0.402032  62af12f4-9856-421d-a18b-16a4d7b39c63  \n\n[5 rows x 27 columns]"
          },
          "execution_count": 173,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/dinaldoap/jit-sdp-data/master/brackets.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>commit_hash</th>\n      <th>timestamp</th>\n      <th>fixes</th>\n      <th>fix</th>\n      <th>ns</th>\n      <th>nd</th>\n      <th>nf</th>\n      <th>entrophy</th>\n      <th>la</th>\n      <th>ld</th>\n      <th>lt</th>\n      <th>ndev</th>\n      <th>age</th>\n      <th>nuc</th>\n      <th>exp</th>\n      <th>rexp</th>\n      <th>sexp</th>\n      <th>contains_bug</th>\n      <th>commit_hash_fix</th>\n      <th>timestamp_fix</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>17571</td>\n      <td>637d7f4ffa0f2396c2fb61a5e51b9b980f47a2c2</td>\n      <td>1323292816</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>23.0</td>\n      <td>3.630787</td>\n      <td>3754.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>0.000000</td>\n      <td>21.0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <td>17570</td>\n      <td>c8142d2dc17fc1d3777689d67d32d010f5d8dfa7</td>\n      <td>1323292845</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.811278</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>23.5</td>\n      <td>0.000000</td>\n      <td>22.0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <td>17569</td>\n      <td>af90ea5adf06c935ce1d5db4ce996054c94aeed7</td>\n      <td>1323294546</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.019688</td>\n      <td>1.0</td>\n      <td>25.0</td>\n      <td>51.793651</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <td>17568</td>\n      <td>82f3f98077bde9ac7c4ff285c593a2f351da5bf2</td>\n      <td>1323295924</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>31.0</td>\n      <td>1.0</td>\n      <td>0.035972</td>\n      <td>1.0</td>\n      <td>26.0</td>\n      <td>28.799228</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <td>17567</td>\n      <td>a454a7bce095b18da240cddf844bfea5a334b7cb</td>\n      <td>1323301755</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0.000000</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                                    commit_hash   timestamp fixes    fix   ns  \\\n17571  637d7f4ffa0f2396c2fb61a5e51b9b980f47a2c2  1323292816   NaN  False  2.0   \n17570  c8142d2dc17fc1d3777689d67d32d010f5d8dfa7  1323292845   NaN  False  2.0   \n17569  af90ea5adf06c935ce1d5db4ce996054c94aeed7  1323294546   NaN   True  1.0   \n17568  82f3f98077bde9ac7c4ff285c593a2f351da5bf2  1323295924   NaN  False  1.0   \n17567  a454a7bce095b18da240cddf844bfea5a334b7cb  1323301755   NaN  False  1.0   \n\n        nd    nf  entrophy      la   ld    lt  ndev       age  nuc   exp  \\\n17571  5.0  23.0  3.630787  3754.0  0.0   0.0   1.0  0.000000  0.0  11.0   \n17570  2.0   2.0  0.811278     4.0  0.0   0.0   1.0  0.000000  0.0  23.5   \n17569  1.0   1.0  0.000000     1.0  1.0   3.0   1.0  0.019688  1.0  25.0   \n17568  1.0   1.0  0.000000     2.0  3.0  31.0   1.0  0.035972  1.0  26.0   \n17567  1.0   2.0  0.000000     5.0  0.0   0.0   1.0  0.000000  0.0   0.5   \n\n            rexp  sexp  contains_bug commit_hash_fix  timestamp_fix  \n17571   0.000000  21.0             0             NaN            NaN  \n17570   0.000000  22.0             0             NaN            NaN  \n17569  51.793651   2.0             0             NaN            NaN  \n17568  28.799228   3.0             0             NaN            NaN  \n17567   0.000000   1.0             0             NaN            NaN  "
          },
          "execution_count": 174,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_col = 'contains_bug'\n",
        "features_cols = ['fix', 'ns', 'nd', 'nf', 'entrophy', 'la', 'ld', 'lt', 'ndev', 'age', 'nuc', 'exp', 'rexp', 'sexp']\n",
        "preprocess_cols = ['commit_hash', 'author_date_unix_timestamp', 'fixes'] + features_cols + [label_col]\n",
        "df_preprocess = df[preprocess_cols].copy()\n",
        "# filter rows with missing data \n",
        "df_preprocess = df_preprocess.dropna(subset=['fix'])\n",
        "# timeline order\n",
        "df_preprocess = df_preprocess[::-1]\n",
        "# contains_bug\n",
        "df_preprocess[label_col] = df_preprocess[label_col].astype('int')\n",
        "# timestamp\n",
        "df_preprocess = df_preprocess.rename(columns={'author_date_unix_timestamp': 'timestamp'})\n",
        "# fixes\n",
        "df_preprocess['commit_hash_fix'] = df_preprocess['fixes'].dropna().apply(lambda x: re.findall('\\\\b\\\\w+\\\\b', x)[0])\n",
        "df_fix = df_preprocess[['commit_hash', 'timestamp']].set_index('commit_hash')\n",
        "df_preprocess = df_preprocess.join(df_fix, on='commit_hash_fix', how='left', rsuffix='_fix')\n",
        "df_preprocess.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {},
      "outputs": [],
      "source": [
        "prequential_cols = ['timestamp', 'timestamp_fix'] + features_cols + [label_col]\n",
        "df_prequential = df_preprocess[prequential_cols].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_pipeline():\n",
        "    scaler = StandardScaler()\n",
        "    criterion = nn.BCELoss()\n",
        "    classifier = Classifier(input_size=len(features_cols), hidden_size=len(features_cols) // 2, drop_prob=0.2)\n",
        "    optimizer = optim.Adam(params=classifier.parameters(), lr=0.003)\n",
        "    return Pipeline(steps=[scaler], classifier=classifier, optimizer=optimizer, criterion=criterion,\n",
        "                    max_epochs=50, batch_size=512, fading_factor=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {},
      "outputs": [],
      "source": [
        "  def evaluate(label, targets, predictions):\n",
        "    gmean, recalls = metrics.gmean_recalls(targets, predictions)\n",
        "    print('{} g-mean: {}, recalls: {}'.format(label, gmean, recalls))\n",
        "\n",
        "  def evaluate_train_test(seq, targets_train, predictions_train, targets_test, predictions_test, targets_unlabeled, predictions_unlabeled):\n",
        "    print('Sequential: {}'.format(seq))\n",
        "    evaluate('Train', targets_train, predictions_train)\n",
        "    evaluate('Test', targets_test, predictions_test)    \n",
        "    evaluate('Unlabeled', targets_unlabeled, predictions_unlabeled)\n",
        "    train_label_total, train_label_normal, train_label_bug = metrics.proportions(targets_train)\n",
        "    train_pred_total, train_pred_normal, train_pred_bug = metrics.proportions(predictions_train)\n",
        "    test_label_total, test_label_normal, test_label_bug = metrics.proportions(targets_test)\n",
        "    test_pred_total, test_pred_normal, test_pred_bug = metrics.proportions(predictions_test)\n",
        "    unlabeled_total, unlabeled_normal, unlabeled_bug = metrics.proportions(predictions_unlabeled)\n",
        "    print('Train label total: {}, normal: {:.2f}%, bug: {:.2f}%'.format(train_label_total, train_label_normal, train_label_bug))\n",
        "    print('Train pred total: {}, normal: {:.2f}%, bug: {:.2f}%'.format(train_pred_total, train_pred_normal, train_pred_bug))\n",
        "    print('Test label total: {}, normal: {:.2f}%, bug: {:.2f}%'.format(test_label_total, test_label_normal, test_label_bug))\n",
        "    print('Test pred total: {}, normal: {:.2f}%, bug: {:.2f}%'.format(test_pred_total, test_pred_normal, test_pred_bug))\n",
        "    print('Unlabeled pred total: {}, normal: {:.2f}%, bug: {:.2f}%'.format(unlabeled_total, unlabeled_normal, unlabeled_bug))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Sequential: 1500\nTrain g-mean: 0.8677497857802383, recalls: [0.94857143 0.79381443]\nTest g-mean: 0.728525285205025, recalls: [0.55619597 0.95424837]\nUnlabeled g-mean: 0.0, recalls: [0.5058698 0.       ]\nTrain label total: 563, normal: 0.31%, bug: 0.69%\nTrain pred total: 563, normal: 0.44%, bug: 0.56%\nTest label total: 500, normal: 0.69%, bug: 0.31%\nTest pred total: 500, normal: 0.40%, bug: 0.60%\nUnlabeled pred total: 937, normal: 0.51%, bug: 0.49%\nSequential: 2000\nTrain g-mean: 0.827379240401869, recalls: [0.90909091 0.75301205]\nTest g-mean: 0.7331776095289766, recalls: [0.55434783 0.96969697]\nUnlabeled g-mean: 0.0, recalls: [0.51152482 0.        ]\nTrain label total: 872, normal: 0.43%, bug: 0.57%\nTrain pred total: 872, normal: 0.53%, bug: 0.47%\nTest label total: 500, normal: 0.74%, bug: 0.26%\nTest pred total: 500, normal: 0.42%, bug: 0.58%\nUnlabeled pred total: 1128, normal: 0.51%, bug: 0.49%\nSequential: 2500\nTrain g-mean: 0.8190013962392685, recalls: [0.87213115 0.76910828]\nTest g-mean: 0.6900614695681337, recalls: [0.51253482 0.92907801]\nUnlabeled g-mean: 0.0, recalls: [0.53803487 0.        ]\nTrain label total: 1238, normal: 0.49%, bug: 0.51%\nTrain pred total: 1238, normal: 0.55%, bug: 0.45%\nTest label total: 500, normal: 0.72%, bug: 0.28%\nTest pred total: 500, normal: 0.39%, bug: 0.61%\nUnlabeled pred total: 1262, normal: 0.54%, bug: 0.46%\nSequential: 3000\nTrain g-mean: 0.7802415024066771, recalls: [0.79796265 0.76291391]\nTest g-mean: 0.7084054173240897, recalls: [0.51470588 0.975     ]\nUnlabeled g-mean: 0.0, recalls: [0.51546392 0.        ]\nTrain label total: 1933, normal: 0.61%, bug: 0.39%\nTrain pred total: 1933, normal: 0.58%, bug: 0.42%\nTest label total: 500, normal: 0.68%, bug: 0.32%\nTest pred total: 500, normal: 0.36%, bug: 0.64%\nUnlabeled pred total: 1067, normal: 0.52%, bug: 0.48%\nSequential: 3500\nTrain g-mean: 0.7754842210641872, recalls: [0.73030143 0.82346241]\nTest g-mean: 0.6820987220825638, recalls: [0.51466667 0.904     ]\nUnlabeled g-mean: 0.0, recalls: [0.47879617 0.        ]\nTrain label total: 2769, normal: 0.68%, bug: 0.32%\nTrain pred total: 2769, normal: 0.55%, bug: 0.45%\nTest label total: 500, normal: 0.75%, bug: 0.25%\nTest pred total: 500, normal: 0.41%, bug: 0.59%\nUnlabeled pred total: 731, normal: 0.48%, bug: 0.52%\nSequential: 4000\nTrain g-mean: 0.782018899918296, recalls: [0.72522523 0.84326019]\nTest g-mean: 0.7338767100626841, recalls: [0.58379888 0.92253521]\nUnlabeled g-mean: 0.0, recalls: [0.5236938 0.       ]\nTrain label total: 3177, normal: 0.70%, bug: 0.30%\nTrain pred total: 3177, normal: 0.55%, bug: 0.45%\nTest label total: 500, normal: 0.72%, bug: 0.28%\nTest pred total: 500, normal: 0.44%, bug: 0.56%\nUnlabeled pred total: 823, normal: 0.52%, bug: 0.48%\nSequential: 4500\nTrain g-mean: 0.7953121398228848, recalls: [0.75041322 0.84289746]\nTest g-mean: 0.7442392382997081, recalls: [0.60683761 0.91275168]\nUnlabeled g-mean: 0.0, recalls: [0.53982301 0.        ]\nTrain label total: 3483, normal: 0.69%, bug: 0.31%\nTrain pred total: 3483, normal: 0.57%, bug: 0.43%\nTest label total: 500, normal: 0.70%, bug: 0.30%\nTest pred total: 500, normal: 0.45%, bug: 0.55%\nUnlabeled pred total: 1017, normal: 0.54%, bug: 0.46%\nSequential: 5000\nTrain g-mean: 0.7830558788290762, recalls: [0.73418169 0.8351836 ]\nTest g-mean: 0.7059009136997456, recalls: [0.52077562 0.95683453]\nUnlabeled g-mean: 0.0, recalls: [0.476 0.   ]\nTrain label total: 4000, normal: 0.71%, bug: 0.29%\nTrain pred total: 4000, normal: 0.57%, bug: 0.43%\nTest label total: 500, normal: 0.72%, bug: 0.28%\nTest pred total: 500, normal: 0.39%, bug: 0.61%\nUnlabeled pred total: 1000, normal: 0.48%, bug: 0.52%\nSequential: 5500\nTrain g-mean: 0.7893313773574212, recalls: [0.75614367 0.82397572]\nTest g-mean: 0.7298632257720405, recalls: [0.54188482 0.98305085]\nUnlabeled g-mean: 0.0, recalls: [0.4702381 0.       ]\nTrain label total: 4492, normal: 0.71%, bug: 0.29%\nTrain pred total: 4492, normal: 0.59%, bug: 0.41%\nTest label total: 500, normal: 0.76%, bug: 0.24%\nTest pred total: 500, normal: 0.42%, bug: 0.58%\nUnlabeled pred total: 1008, normal: 0.47%, bug: 0.53%\nSequential: 6000\nTrain g-mean: 0.7871216095600437, recalls: [0.73030558 0.84835779]\nTest g-mean: 0.6547160275848827, recalls: [0.47021944 0.91160221]\nUnlabeled g-mean: 0.0, recalls: [0.48702595 0.        ]\nTrain label total: 4998, normal: 0.71%, bug: 0.29%\nTrain pred total: 4998, normal: 0.56%, bug: 0.44%\nTest label total: 500, normal: 0.64%, bug: 0.36%\nTest pred total: 500, normal: 0.33%, bug: 0.67%\nUnlabeled pred total: 1002, normal: 0.49%, bug: 0.51%\nSequential: 6500\nTrain g-mean: 0.7852786050412288, recalls: [0.71729519 0.85970532]\nTest g-mean: 0.6859163822379954, recalls: [0.48181818 0.97647059]\nUnlabeled g-mean: 0.0, recalls: [0.47897623 0.        ]\nTrain label total: 5406, normal: 0.71%, bug: 0.29%\nTrain pred total: 5406, normal: 0.55%, bug: 0.45%\nTest label total: 500, normal: 0.66%, bug: 0.34%\nTest pred total: 500, normal: 0.33%, bug: 0.67%\nUnlabeled pred total: 1094, normal: 0.48%, bug: 0.52%\nSequential: 7000\nTrain g-mean: 0.7819691669805963, recalls: [0.71275802 0.85790094]\nTest g-mean: 0.6839806493744571, recalls: [0.48969072 0.95535714]\nUnlabeled g-mean: 0.0, recalls: [0.48168355 0.        ]\nTrain label total: 5717, normal: 0.70%, bug: 0.30%\nTrain pred total: 5717, normal: 0.54%, bug: 0.46%\nTest label total: 500, normal: 0.78%, bug: 0.22%\nTest pred total: 500, normal: 0.39%, bug: 0.61%\nUnlabeled pred total: 1283, normal: 0.48%, bug: 0.52%\nSequential: 7500\nTrain g-mean: 0.7942278892768422, recalls: [0.7371122  0.85576923]\nTest g-mean: 0.7071067811865476, recalls: [0.5 1. ]\nUnlabeled g-mean: 0.0, recalls: [0.45743945 0.        ]\nTrain label total: 6055, normal: 0.71%, bug: 0.29%\nTrain pred total: 6055, normal: 0.56%, bug: 0.44%\nTest label total: 500, normal: 0.79%, bug: 0.21%\nTest pred total: 500, normal: 0.40%, bug: 0.60%\nUnlabeled pred total: 1445, normal: 0.46%, bug: 0.54%\n"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-178-7b972ff98d2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mpredictions_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/workspace/jitsdp/pipeline.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msampled_train_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# split dataset in chunks for testing and iterate over them (chunk from current to current + interval or end)\n",
        "# the previous chunks are used for training (chunks from start to current)\n",
        "seconds_by_day = 24 * 60 * 60\n",
        "verification_latency = 90 * seconds_by_day # seconds\n",
        "interval = 500 # commits\n",
        "end = len(df_prequential) # last commit\n",
        "n_chunks = math.ceil(end / interval)\n",
        "end = n_chunks * interval # last chunk end\n",
        "start = end - (n_chunks - 3) * interval # fifth chunk start\n",
        "#start = end - interval # last chunk start\n",
        "\n",
        "pipeline = create_pipeline()\n",
        "pipeline.save()\n",
        "predictions = []\n",
        "for current in range(start, end, interval):\n",
        "#for current in range(start, start+1, interval):\n",
        "    df_train = df_prequential[:current].copy()\n",
        "    df_test = df_prequential[current:min(current + interval, end)].copy()\n",
        "    # check if fix has been done (bug) or verification latency has passed (normal), otherwise exclude commit\n",
        "    train_timestamp = df_train['timestamp'].max()\n",
        "    df_train[label_col] = df_train.apply(lambda row: 1 if row.timestamp_fix <= train_timestamp else (0 if row.timestamp <= train_timestamp - verification_latency else None), axis='columns')\n",
        "    df_unlabeled = df_train[pd.isnull(df_train[label_col])]\n",
        "    df_train = df_train.dropna(subset=[label_col])\n",
        "    df_train[label_col] = df_train[label_col].astype('int')\n",
        "    # convert to numpy array\n",
        "    X_train = df_train[features_cols].values\n",
        "    y_train = df_train[label_col].values\n",
        "    X_test = df_test[features_cols].values\n",
        "    y_test = df_test[label_col].values\n",
        "    X_unlabeled = df_unlabeled[features_cols].values\n",
        "    y_unlabeled = np.zeros(len(X_unlabeled), dtype=np.int64)\n",
        "    # train and evaluate\n",
        "    pipeline = create_pipeline()\n",
        "    pipeline.load()\n",
        "    pipeline.train(X_train, y_train)\n",
        "    pipeline.save()\n",
        "    predictions_test = pipeline.predict(X_test)    \n",
        "    evaluate_train_test(current, y_train, pipeline.predict(X_train), y_test, predictions_test, y_unlabeled, pipeline.predict(X_unlabeled))\n",
        "    predictions.append(predictions_test)\n",
        "\n",
        "predictions = np.concatenate(predictions)\n",
        "targets = df_prequential[label_col][start:].values\n",
        "evaluate('Full test', targets, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "L_t4Gh43GYWl"
      },
      "outputs": [],
      "source": []
    }
  ]
}