{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JIT-SDP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dinaldoap/jit-sdp-nn/blob/master/notebook/mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import random\n",
        "from scipy.stats import mstats\n",
        "\n",
        "from jitsdp import metrics\n",
        "from jitsdp.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fix</th>\n      <th>ns</th>\n      <th>nd</th>\n      <th>nf</th>\n      <th>entrophy</th>\n      <th>la</th>\n      <th>ld</th>\n      <th>lt</th>\n      <th>ndev</th>\n      <th>age</th>\n      <th>nuc</th>\n      <th>exp</th>\n      <th>rexp</th>\n      <th>sexp</th>\n      <th>contains_bug</th>\n      <th>author_date_unix_timestamp</th>\n      <th>commit_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>False</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>202</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>True</td>\n      <td>1293840523</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>False</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.784992</td>\n      <td>28</td>\n      <td>19</td>\n      <td>103.0</td>\n      <td>1</td>\n      <td>-244.640741</td>\n      <td>3</td>\n      <td>3.5</td>\n      <td>0.996934</td>\n      <td>4</td>\n      <td>True</td>\n      <td>1293853015</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>False</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>84</td>\n      <td>22</td>\n      <td>189.0</td>\n      <td>1</td>\n      <td>-244.640613</td>\n      <td>4</td>\n      <td>7.0</td>\n      <td>0.995912</td>\n      <td>7</td>\n      <td>True</td>\n      <td>1293857524</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>True</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>8</td>\n      <td>7</td>\n      <td>251.0</td>\n      <td>1</td>\n      <td>2.775000</td>\n      <td>5</td>\n      <td>8.0</td>\n      <td>1.360360</td>\n      <td>8</td>\n      <td>True</td>\n      <td>1294097284</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>False</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>205</td>\n      <td>79</td>\n      <td>252.0</td>\n      <td>1</td>\n      <td>0.174444</td>\n      <td>6</td>\n      <td>9.0</td>\n      <td>6.732484</td>\n      <td>9</td>\n      <td>True</td>\n      <td>1294112356</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "     fix  ns  nd  nf  entrophy   la  ld     lt  ndev         age  nuc  exp  \\\n0  False   1   1   1  0.000000  202   0    0.0     1    0.000000    0  0.0   \n1  False   1   2   2  0.784992   28  19  103.0     1 -244.640741    3  3.5   \n2  False   1   1   1  0.000000   84  22  189.0     1 -244.640613    4  7.0   \n3   True   1   1   1  0.000000    8   7  251.0     1    2.775000    5  8.0   \n4  False   1   1   1  0.000000  205  79  252.0     1    0.174444    6  9.0   \n\n       rexp  sexp  contains_bug  author_date_unix_timestamp  commit_type  \n0  0.000000     0          True                  1293840523            2  \n1  0.996934     4          True                  1293853015            2  \n2  0.995912     7          True                  1293857524            2  \n3  1.360360     8          True                  1294097284            2  \n4  6.732484     9          True                  1294112356            2  "
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/dinaldoap/jit-sdp-data/master/neutron.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "/home/pytorch/.conda/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n"
        }
      ],
      "source": [
        "df = df[df['commit_type'] != 3]\n",
        "#df = df.sample(frac=1)\n",
        "label_col = 'contains_bug'\n",
        "features_cols = ['fix', 'ns', 'nd', 'nf', 'entrophy', 'la', 'ld', 'lt', 'ndev', 'age', 'nuc', 'exp', 'rexp', 'sexp']\n",
        "X = df[features_cols]\n",
        "X['fix'] = X['fix'].astype('int')\n",
        "X = X.values\n",
        "y = df[label_col]\n",
        "y = y.astype('int')\n",
        "y = y.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "[[  0.   1.   1.   1.   0. 202.   0.   0.   1.   0.   0.   0.   0.   0.]]\n[1]\n"
        }
      ],
      "source": [
        "print(X[:1])\n",
        "print(y[:1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_index = int( len(X) * 0.9 )\n",
        "X_train, y_train = X[:test_index], y[:test_index]\n",
        "X_test, y_test = X[test_index:], y[test_index:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "[[  0.   1.   1.   1.   0. 202.   0.   0.   1.   0.   0.   0.   0.   0.]]\n[[  1.         1.         2.         2.         0.995253  31.\n    6.        -3.5       32.       141.783623   4.         1.5\n    1.00529    1.      ]]\n"
        }
      ],
      "source": [
        "print(X_train[:1])\n",
        "print(X_test[:1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "mean_train = X_train.mean(axis=0)\n",
        "std_train = X_train.std(axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "[2.17309340e-01 6.27420737e-01 2.12002285e+00 3.00736932e+00\n 5.83037563e-01 2.42894316e+02 2.26149329e+02 4.52423502e+02\n 6.93547558e+01 1.65930550e+01 7.83848615e+01 2.32328620e+02\n 1.94493223e+00 1.45917624e+02]\n[4.12414829e-01 6.91897781e-01 6.83150469e+00 1.51382471e+01\n 1.05340297e+00 3.56071902e+03 8.51085459e+03 1.51858424e+03\n 8.35065665e+01 5.33612416e+01 4.28584853e+02 6.31941494e+02\n 2.85733763e+01 4.74041454e+02]\n"
        }
      ],
      "source": [
        "print(mean_train)\n",
        "print(std_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = (X_train - mean_train) / std_train\n",
        "X_test = (X_test - mean_train) / std_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "[[-0.52691932  0.53848888 -0.16394966 -0.13260249 -0.55348008 -0.01148485\n  -0.02657187 -0.29792453 -0.81855546 -0.31095706 -0.18289228 -0.36764261\n  -0.06806799 -0.30781617]]\n[[ 1.89782376  0.53848888 -0.01756902 -0.06654465  0.3913179  -0.05950886\n  -0.02586689 -0.30022931 -0.44732717  2.34609549 -0.17355924 -0.36526897\n  -0.03288524 -0.30570665]]\n"
        }
      ],
      "source": [
        "print(X_train[:1])\n",
        "print(X_test[:1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Classifier(nn.Module):\n",
        "  FILENAME = 'models/classifier.cpt'\n",
        "  def __init__(self, input_size, hidden_size, drop_prob, epoch=None, val_gmean=None):\n",
        "    super(Classifier, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.drop_prob = drop_prob\n",
        "    self.epoch = epoch\n",
        "    self.val_gmean = val_gmean\n",
        "    self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "    self.fcout = nn.Linear(hidden_size, 1)\n",
        "    self.dropout = nn.Dropout(drop_prob)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = torch.relu(self.fc1(x))\n",
        "    x = self.dropout(x)\n",
        "    x = torch.sigmoid(self.fcout(x))\n",
        "    return x\n",
        "\n",
        "  def save(self):\n",
        "    checkpoint = {\n",
        "        'input_size': self.input_size,\n",
        "        'hidden_size': self.hidden_size,\n",
        "        'drop_prob': self.drop_prob,\n",
        "        'val_gmean': self.val_gmean,\n",
        "        'epoch': self.epoch,\n",
        "        'state_dict': self.state_dict()\n",
        "    }\n",
        "    with open(Classifier.FILENAME, 'wb') as f:\n",
        "      torch.save(checkpoint, f)\n",
        "\n",
        "  def load(self):\n",
        "    with open(Classifier.FILENAME, 'rb') as f:\n",
        "      checkpoint = torch.load(f)\n",
        "      self.input_size = checkpoint['input_size']\n",
        "      self.hidden_size = checkpoint['hidden_size']\n",
        "      self.drop_prob = checkpoint['drop_prob']\n",
        "      self.epoch = checkpoint['epoch']\n",
        "      self.val_gmean = checkpoint['val_gmean']\n",
        "      self.load_state_dict(checkpoint['state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": "Classifier(\n  (fc1): Linear(in_features=14, out_features=14, bias=True)\n  (fcout): Linear(in_features=14, out_features=1, bias=True)\n  (dropout): Dropout(p=0.5, inplace=False)\n)"
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier = Classifier(input_size=X.shape[1], hidden_size=X.shape[1], drop_prob=0.5)\n",
        "classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": "Classifier(\n  (fc1): Linear(in_features=14, out_features=14, bias=True)\n  (fcout): Linear(in_features=14, out_features=1, bias=True)\n  (dropout): Dropout(p=0.5, inplace=False)\n)"
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier.save()\n",
        "classifier.load()\n",
        "classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(params=classifier.parameters(), lr=0.003)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Epoch: 0, Train loss: 0.6450117792401995, Train g-mean: 0.7963975383109918, Val g-mean: None\nEpoch: 1, Train loss: 0.5314305687680536, Train g-mean: 0.7955219140813922, Val g-mean: None\nEpoch: 2, Train loss: 0.4578474614300463, Train g-mean: 0.8036099847303619, Val g-mean: None\nEpoch: 3, Train loss: 0.4372924766463272, Train g-mean: 0.813510239661603, Val g-mean: None\nEpoch: 4, Train loss: 0.4246317715915107, Train g-mean: 0.8154368901866548, Val g-mean: None\nEpoch: 5, Train loss: 0.41697042235724147, Train g-mean: 0.8167487085491466, Val g-mean: None\nEpoch: 6, Train loss: 0.4135374040969758, Train g-mean: 0.8216606898397752, Val g-mean: None\nEpoch: 7, Train loss: 0.40417653893166655, Train g-mean: 0.8220552674403502, Val g-mean: None\nEpoch: 8, Train loss: 0.40199231351407766, Train g-mean: 0.8258103613053495, Val g-mean: None\nEpoch: 9, Train loss: 0.40487877534826383, Train g-mean: 0.8294730428034831, Val g-mean: None\nEpoch: 10, Train loss: 0.39921319683591516, Train g-mean: 0.8323006911654154, Val g-mean: None\nEpoch: 11, Train loss: 0.39596936452962106, Train g-mean: 0.8328351689510127, Val g-mean: None\nEpoch: 12, Train loss: 0.39220520352993044, Train g-mean: 0.8332050262698509, Val g-mean: None\nEpoch: 13, Train loss: 0.3868056815282713, Train g-mean: 0.837345436972033, Val g-mean: None\nEpoch: 14, Train loss: 0.395571075965723, Train g-mean: 0.8378541424668223, Val g-mean: None\nEpoch: 15, Train loss: 0.38908733365336373, Train g-mean: 0.8358568657289553, Val g-mean: None\nEpoch: 16, Train loss: 0.39245418947009797, Train g-mean: 0.8355767814724459, Val g-mean: None\nEpoch: 17, Train loss: 0.39051950523997164, Train g-mean: 0.8371250689709595, Val g-mean: None\nEpoch: 18, Train loss: 0.37984606213505634, Train g-mean: 0.8384329112864799, Val g-mean: None\nEpoch: 19, Train loss: 0.3835092432689484, Train g-mean: 0.8370728654404428, Val g-mean: None\nEpoch: 20, Train loss: 0.38713814175523975, Train g-mean: 0.840169303094486, Val g-mean: None\nEpoch: 21, Train loss: 0.3918915028675391, Train g-mean: 0.8390605165360436, Val g-mean: None\nEpoch: 22, Train loss: 0.3787823181359654, Train g-mean: 0.8428478132473759, Val g-mean: None\nEpoch: 23, Train loss: 0.3833176259796071, Train g-mean: 0.8419878952060756, Val g-mean: None\nEpoch: 24, Train loss: 0.376740311908155, Train g-mean: 0.8425056748121, Val g-mean: None\nEpoch: 25, Train loss: 0.37231997862677996, Train g-mean: 0.843298255324196, Val g-mean: None\nEpoch: 26, Train loss: 0.3826156525995678, Train g-mean: 0.8420962408414444, Val g-mean: None\nEpoch: 27, Train loss: 0.37082250705556175, Train g-mean: 0.8438052243843591, Val g-mean: None\nEpoch: 28, Train loss: 0.3822551545050019, Train g-mean: 0.8466178194012389, Val g-mean: None\nEpoch: 29, Train loss: 0.37010128122439345, Train g-mean: 0.846753246675385, Val g-mean: None\nEpoch: 30, Train loss: 0.3739970609749698, Train g-mean: 0.8466101411662516, Val g-mean: None\nEpoch: 31, Train loss: 0.3820371797686683, Train g-mean: 0.8477646038416197, Val g-mean: None\nEpoch: 32, Train loss: 0.37284794157745116, Train g-mean: 0.843146067582038, Val g-mean: None\nEpoch: 33, Train loss: 0.37688597176926525, Train g-mean: 0.8442801314551471, Val g-mean: None\nEpoch: 34, Train loss: 0.36824960769200815, Train g-mean: 0.8454902665280027, Val g-mean: None\nEpoch: 35, Train loss: 0.37628613916493153, Train g-mean: 0.8446739200383708, Val g-mean: None\nEpoch: 36, Train loss: 0.3817550392399109, Train g-mean: 0.8467396247813385, Val g-mean: None\nEpoch: 37, Train loss: 0.3786119916650508, Train g-mean: 0.845160159903581, Val g-mean: None\nEpoch: 38, Train loss: 0.3748668928901719, Train g-mean: 0.8443822286232979, Val g-mean: None\nEpoch: 39, Train loss: 0.3713291795479694, Train g-mean: 0.8456169614468685, Val g-mean: None\nEpoch: 40, Train loss: 0.3752861497272408, Train g-mean: 0.8489174447204905, Val g-mean: None\nEpoch: 41, Train loss: 0.38234586851219154, Train g-mean: 0.8449073017113142, Val g-mean: None\nEpoch: 42, Train loss: 0.37091757182178603, Train g-mean: 0.8483261549348018, Val g-mean: None\nEpoch: 43, Train loss: 0.36804267546219416, Train g-mean: 0.844303945575817, Val g-mean: None\nEpoch: 44, Train loss: 0.371756510161412, Train g-mean: 0.8468355591705778, Val g-mean: None\nEpoch: 45, Train loss: 0.37494940633498636, Train g-mean: 0.8465879749148455, Val g-mean: None\nEpoch: 46, Train loss: 0.3736207181711773, Train g-mean: 0.845909653114944, Val g-mean: None\nEpoch: 47, Train loss: 0.3723443244028653, Train g-mean: 0.8455043428531975, Val g-mean: None\nEpoch: 48, Train loss: 0.3646016583389571, Train g-mean: 0.8474117950282655, Val g-mean: None\nEpoch: 49, Train loss: 0.3723947078430838, Train g-mean: 0.8466656438373773, Val g-mean: None\nEpoch: 50, Train loss: 0.3723034951529168, Train g-mean: 0.8495436720272228, Val g-mean: None\nEpoch: 51, Train loss: 0.3710223226134018, Train g-mean: 0.8472597331329312, Val g-mean: None\nEpoch: 52, Train loss: 0.37723977165104106, Train g-mean: 0.8476522136642409, Val g-mean: None\nEpoch: 53, Train loss: 0.36977788828573943, Train g-mean: 0.8507021420644661, Val g-mean: None\nEpoch: 54, Train loss: 0.37321683679954276, Train g-mean: 0.8491415264818113, Val g-mean: None\nEpoch: 55, Train loss: 0.36531996894874347, Train g-mean: 0.8498789407578698, Val g-mean: None\nEpoch: 56, Train loss: 0.3700803237781633, Train g-mean: 0.8486648144048691, Val g-mean: None\nEpoch: 57, Train loss: 0.36249697809453724, Train g-mean: 0.8491454635751758, Val g-mean: None\nEpoch: 58, Train loss: 0.3644578467110895, Train g-mean: 0.8489736426164974, Val g-mean: None\nEpoch: 59, Train loss: 0.36897274428975047, Train g-mean: 0.848969748266187, Val g-mean: None\nEpoch: 60, Train loss: 0.366292509741548, Train g-mean: 0.8504804167437874, Val g-mean: None\nEpoch: 61, Train loss: 0.35956782367419526, Train g-mean: 0.8491406943285468, Val g-mean: None\nEpoch: 62, Train loss: 0.37031468501164555, Train g-mean: 0.8490985435757453, Val g-mean: None\nEpoch: 63, Train loss: 0.37136836300307063, Train g-mean: 0.8517179190424572, Val g-mean: None\nEpoch: 64, Train loss: 0.37201946333760694, Train g-mean: 0.8508383627254811, Val g-mean: None\nEpoch: 65, Train loss: 0.36368217364825367, Train g-mean: 0.8489486528611956, Val g-mean: None\nEpoch: 66, Train loss: 0.3725642074561907, Train g-mean: 0.8491984102964403, Val g-mean: None\nEpoch: 67, Train loss: 0.3674947069072064, Train g-mean: 0.8498115035132973, Val g-mean: None\nEpoch: 68, Train loss: 0.3688152953158768, Train g-mean: 0.8501197967519564, Val g-mean: None\nEpoch: 69, Train loss: 0.36003194770407376, Train g-mean: 0.8487881236193584, Val g-mean: None\nEpoch: 70, Train loss: 0.3618282007379735, Train g-mean: 0.8476871135214878, Val g-mean: None\nEpoch: 71, Train loss: 0.35793171844937516, Train g-mean: 0.8495530424745088, Val g-mean: None\nEpoch: 72, Train loss: 0.36374326476655067, Train g-mean: 0.8501306274307773, Val g-mean: None\nEpoch: 73, Train loss: 0.36770467302038606, Train g-mean: 0.8517382523920058, Val g-mean: None\nEpoch: 74, Train loss: 0.3654541853895739, Train g-mean: 0.8504209544518561, Val g-mean: None\nEpoch: 75, Train loss: 0.36541458420478434, Train g-mean: 0.8511708380737868, Val g-mean: None\nEpoch: 76, Train loss: 0.36640950000073885, Train g-mean: 0.8527577484215858, Val g-mean: None\nEpoch: 77, Train loss: 0.361122511669507, Train g-mean: 0.8492670221504587, Val g-mean: None\nEpoch: 78, Train loss: 0.3679504724583316, Train g-mean: 0.8478826640432691, Val g-mean: None\nEpoch: 79, Train loss: 0.36757705561388476, Train g-mean: 0.8511316280754881, Val g-mean: None\nEpoch: 80, Train loss: 0.36961855149044, Train g-mean: 0.8501750631184664, Val g-mean: None\nEpoch: 81, Train loss: 0.3639713709285638, Train g-mean: 0.8517226194722476, Val g-mean: None\nEpoch: 82, Train loss: 0.3664560467990545, Train g-mean: 0.8513452603159477, Val g-mean: None\nEpoch: 83, Train loss: 0.3590336539943795, Train g-mean: 0.8517373083926455, Val g-mean: None\nEpoch: 84, Train loss: 0.3651994793148262, Train g-mean: 0.8509713193637488, Val g-mean: None\nEpoch: 85, Train loss: 0.3663590057365424, Train g-mean: 0.8516122846498824, Val g-mean: None\nEpoch: 86, Train loss: 0.364800351300899, Train g-mean: 0.8512074314787953, Val g-mean: None\nEpoch: 87, Train loss: 0.3671427936054146, Train g-mean: 0.8517299065496202, Val g-mean: None\nEpoch: 88, Train loss: 0.3661482180036161, Train g-mean: 0.8509848567431756, Val g-mean: None\nEpoch: 89, Train loss: 0.3631528943631679, Train g-mean: 0.8497223257574794, Val g-mean: None\nEpoch: 90, Train loss: 0.37012592392266824, Train g-mean: 0.8522603594094604, Val g-mean: None\nEpoch: 91, Train loss: 0.3664174864510982, Train g-mean: 0.8516039163250423, Val g-mean: None\nEpoch: 92, Train loss: 0.3669416858747468, Train g-mean: 0.8522662023831111, Val g-mean: None\nEpoch: 93, Train loss: 0.3665220114560208, Train g-mean: 0.8524754328759493, Val g-mean: None\nEpoch: 94, Train loss: 0.3596720984236719, Train g-mean: 0.8531557789448755, Val g-mean: None\nEpoch: 95, Train loss: 0.3630413847044999, Train g-mean: 0.8516852209581522, Val g-mean: None\nEpoch: 96, Train loss: 0.3613502898014043, Train g-mean: 0.8517798138619312, Val g-mean: None\nEpoch: 97, Train loss: 0.3571783301892634, Train g-mean: 0.8518209084978255, Val g-mean: None\nEpoch: 98, Train loss: 0.3693986322132257, Train g-mean: 0.8521669755724594, Val g-mean: None\nEpoch: 99, Train loss: 0.36505399966707547, Train g-mean: 0.8520451549354836, Val g-mean: None\nEpoch: 100, Train loss: 0.3481153595516996, Train g-mean: 0.851447110122465, Val g-mean: None\nEpoch: 101, Train loss: 0.3536984683447506, Train g-mean: 0.8524118779453542, Val g-mean: None\nEpoch: 102, Train loss: 0.36194529039908996, Train g-mean: 0.8532335277115662, Val g-mean: None\nEpoch: 103, Train loss: 0.36617171903543516, Train g-mean: 0.8524005995189338, Val g-mean: None\nEpoch: 104, Train loss: 0.36092141530062266, Train g-mean: 0.8515772989229404, Val g-mean: None\nEpoch: 105, Train loss: 0.3617757440354556, Train g-mean: 0.853345450399365, Val g-mean: None\nEpoch: 106, Train loss: 0.3623681358801357, Train g-mean: 0.8510217162997985, Val g-mean: None\nEpoch: 107, Train loss: 0.3666458674621214, Train g-mean: 0.8509682887948911, Val g-mean: None\nEpoch: 108, Train loss: 0.3637498113324291, Train g-mean: 0.853152329238333, Val g-mean: None\nEpoch: 109, Train loss: 0.36690519052689996, Train g-mean: 0.8539663077030557, Val g-mean: None\nEpoch: 110, Train loss: 0.36974256401911965, Train g-mean: 0.8508831863635657, Val g-mean: None\nEpoch: 111, Train loss: 0.3662524510467778, Train g-mean: 0.851977091549636, Val g-mean: None\nEpoch: 112, Train loss: 0.3592743532687276, Train g-mean: 0.8525289046216056, Val g-mean: None\nEpoch: 113, Train loss: 0.35260201169431166, Train g-mean: 0.8509494199098022, Val g-mean: None\nEpoch: 114, Train loss: 0.36811585530592716, Train g-mean: 0.8532599554447812, Val g-mean: None\nEpoch: 115, Train loss: 0.36292868378757115, Train g-mean: 0.8524517599177451, Val g-mean: None\nEpoch: 116, Train loss: 0.36017373786738904, Train g-mean: 0.851822787236458, Val g-mean: None\nEpoch: 117, Train loss: 0.367367077891705, Train g-mean: 0.8535695179033306, Val g-mean: None\nEpoch: 118, Train loss: 0.3625226324236018, Train g-mean: 0.8505653680748738, Val g-mean: None\nEpoch: 119, Train loss: 0.35488044961701015, Train g-mean: 0.8538539806797568, Val g-mean: None\nEpoch: 120, Train loss: 0.35651974415336624, Train g-mean: 0.8535803137168315, Val g-mean: None\nEpoch: 121, Train loss: 0.3658373615672346, Train g-mean: 0.8531853002188744, Val g-mean: None\nEpoch: 122, Train loss: 0.3597552775244774, Train g-mean: 0.851093443739968, Val g-mean: None\nEpoch: 123, Train loss: 0.3670406256372045, Train g-mean: 0.853354513375862, Val g-mean: None\nEpoch: 124, Train loss: 0.36407293142095726, Train g-mean: 0.8522115973354437, Val g-mean: None\nEpoch: 125, Train loss: 0.3692264500859849, Train g-mean: 0.8540840474591763, Val g-mean: None\nEpoch: 126, Train loss: 0.35617982047967534, Train g-mean: 0.8534879281362776, Val g-mean: None\nEpoch: 127, Train loss: 0.3678785133072797, Train g-mean: 0.8541484245813142, Val g-mean: None\nEpoch: 128, Train loss: 0.35476785605211786, Train g-mean: 0.8536102192630425, Val g-mean: None\nEpoch: 129, Train loss: 0.3612611889002038, Train g-mean: 0.8537499078546057, Val g-mean: None\nEpoch: 130, Train loss: 0.3640663845174577, Train g-mean: 0.8533837276796564, Val g-mean: None\nEpoch: 131, Train loss: 0.35882383818522257, Train g-mean: 0.853402257405861, Val g-mean: None\nEpoch: 132, Train loss: 0.3584692104189439, Train g-mean: 0.8525563477245011, Val g-mean: None\nEpoch: 133, Train loss: 0.3571138933259216, Train g-mean: 0.8520543450303447, Val g-mean: None\nEpoch: 134, Train loss: 0.3591143981472594, Train g-mean: 0.8547962390436116, Val g-mean: None\nEpoch: 135, Train loss: 0.36040956603872193, Train g-mean: 0.8501075644133664, Val g-mean: None\nEpoch: 136, Train loss: 0.3578647266760859, Train g-mean: 0.8542552645698835, Val g-mean: None\nEpoch: 137, Train loss: 0.36671414940395636, Train g-mean: 0.8542684760079826, Val g-mean: None\nEpoch: 138, Train loss: 0.3530153112663651, Train g-mean: 0.8548428731922978, Val g-mean: None\nEpoch: 139, Train loss: 0.36235201636113956, Train g-mean: 0.8545859455266303, Val g-mean: None\nEpoch: 140, Train loss: 0.3645528172536005, Train g-mean: 0.8524078265752556, Val g-mean: None\nEpoch: 141, Train loss: 0.3669324284936227, Train g-mean: 0.852343856404704, Val g-mean: None\nEpoch: 142, Train loss: 0.3729360113999538, Train g-mean: 0.8542217559616648, Val g-mean: None\nEpoch: 143, Train loss: 0.36582168088203754, Train g-mean: 0.8525188371199212, Val g-mean: None\nEpoch: 144, Train loss: 0.3608092910181471, Train g-mean: 0.8551875941516032, Val g-mean: None\nEpoch: 145, Train loss: 0.34748562644246356, Train g-mean: 0.8534537440480573, Val g-mean: None\nEpoch: 146, Train loss: 0.35922081710904075, Train g-mean: 0.8552184239163634, Val g-mean: None\nEpoch: 147, Train loss: 0.36060973361617304, Train g-mean: 0.8528586493233296, Val g-mean: None\nEpoch: 148, Train loss: 0.3626311845312476, Train g-mean: 0.854650896304428, Val g-mean: None\nEpoch: 149, Train loss: 0.35341034226965323, Train g-mean: 0.8512350801096451, Val g-mean: None\nEpoch: 150, Train loss: 0.3535683923940861, Train g-mean: 0.8542623863679238, Val g-mean: None\nEpoch: 151, Train loss: 0.36036511794153, Train g-mean: 0.8561715456187148, Val g-mean: None\nEpoch: 152, Train loss: 0.36012063524139015, Train g-mean: 0.8532703387908926, Val g-mean: None\nEpoch: 153, Train loss: 0.35019987086483756, Train g-mean: 0.8534164403788489, Val g-mean: None\nEpoch: 154, Train loss: 0.3662002169688625, Train g-mean: 0.8536036878281386, Val g-mean: None\nEpoch: 155, Train loss: 0.35849448466187456, Train g-mean: 0.8526208489745639, Val g-mean: None\nEpoch: 156, Train loss: 0.36082215037342646, Train g-mean: 0.8536274908400178, Val g-mean: None\nEpoch: 157, Train loss: 0.3582580041108803, Train g-mean: 0.8531792643334012, Val g-mean: None\nEpoch: 158, Train loss: 0.3465659616993106, Train g-mean: 0.85379614015681, Val g-mean: None\nEpoch: 159, Train loss: 0.35555561269637015, Train g-mean: 0.8552386290028594, Val g-mean: None\nEpoch: 160, Train loss: 0.360449965194667, Train g-mean: 0.8533602927435254, Val g-mean: None\nEpoch: 161, Train loss: 0.34893540301197495, Train g-mean: 0.8516380423579192, Val g-mean: None\nEpoch: 162, Train loss: 0.35817905600816685, Train g-mean: 0.8553056014448381, Val g-mean: None\nEpoch: 163, Train loss: 0.3538789517357096, Train g-mean: 0.8525330241633167, Val g-mean: None\nEpoch: 164, Train loss: 0.35724414861393583, Train g-mean: 0.8536031747917604, Val g-mean: None\nEpoch: 165, Train loss: 0.34864486497816377, Train g-mean: 0.853705803038903, Val g-mean: None\nEpoch: 166, Train loss: 0.3632766565374468, Train g-mean: 0.8540403233870464, Val g-mean: None\nEpoch: 167, Train loss: 0.3546519648764586, Train g-mean: 0.8532886527230676, Val g-mean: None\nEpoch: 168, Train loss: 0.3591838532167788, Train g-mean: 0.854195147911251, Val g-mean: None\nEpoch: 169, Train loss: 0.36426745242583786, Train g-mean: 0.8547120905454932, Val g-mean: None\nEpoch: 170, Train loss: 0.36101670815453873, Train g-mean: 0.8546897156021983, Val g-mean: None\nEpoch: 171, Train loss: 0.35393911649894316, Train g-mean: 0.8546480946002974, Val g-mean: None\nEpoch: 172, Train loss: 0.35895874501696984, Train g-mean: 0.8536028189606981, Val g-mean: None\nEpoch: 173, Train loss: 0.36126376714065866, Train g-mean: 0.8552610206189325, Val g-mean: None\nEpoch: 174, Train loss: 0.35564513164638206, Train g-mean: 0.8535212398383305, Val g-mean: None\nEpoch: 175, Train loss: 0.3529053980844017, Train g-mean: 0.8546074123841687, Val g-mean: None\nEpoch: 176, Train loss: 0.34996626222342764, Train g-mean: 0.8541190137873405, Val g-mean: None\nEpoch: 177, Train loss: 0.35145191733161907, Train g-mean: 0.8520719078498147, Val g-mean: None\nEpoch: 178, Train loss: 0.3664872897193887, Train g-mean: 0.8562203627099341, Val g-mean: None\nEpoch: 179, Train loss: 0.36873669866302483, Train g-mean: 0.8552971056258456, Val g-mean: None\nEpoch: 180, Train loss: 0.3496329507497319, Train g-mean: 0.855219925200864, Val g-mean: None\nEpoch: 181, Train loss: 0.3516496122487028, Train g-mean: 0.8561195815197807, Val g-mean: None\nEpoch: 182, Train loss: 0.351103660891759, Train g-mean: 0.8556271829201363, Val g-mean: None\nEpoch: 183, Train loss: 0.3649788200125895, Train g-mean: 0.8533415445389503, Val g-mean: None\nEpoch: 184, Train loss: 0.35726294261860225, Train g-mean: 0.8516507619542203, Val g-mean: None\nEpoch: 185, Train loss: 0.3518921555061134, Train g-mean: 0.8554199911174196, Val g-mean: None\nEpoch: 186, Train loss: 0.36126016753338347, Train g-mean: 0.8554873264032556, Val g-mean: None\nEpoch: 187, Train loss: 0.3602125174026894, Train g-mean: 0.8552887452901012, Val g-mean: None\nEpoch: 188, Train loss: 0.3535009668731156, Train g-mean: 0.855835569751081, Val g-mean: None\nEpoch: 189, Train loss: 0.3539880098231164, Train g-mean: 0.8564563739593126, Val g-mean: None\nEpoch: 190, Train loss: 0.36117293119807337, Train g-mean: 0.8553942065788773, Val g-mean: None\nEpoch: 191, Train loss: 0.35623868070340703, Train g-mean: 0.8540815699376697, Val g-mean: None\nEpoch: 192, Train loss: 0.3586424858122486, Train g-mean: 0.8564537971030631, Val g-mean: None\nEpoch: 193, Train loss: 0.3623587556417483, Train g-mean: 0.852228155614012, Val g-mean: None\nEpoch: 194, Train loss: 0.3595585637652752, Train g-mean: 0.8581374675398334, Val g-mean: None\nEpoch: 195, Train loss: 0.36275251710234335, Train g-mean: 0.8544311281588748, Val g-mean: None\nEpoch: 196, Train loss: 0.3592140228986224, Train g-mean: 0.8546393685603833, Val g-mean: None\nEpoch: 197, Train loss: 0.3618978734568173, Train g-mean: 0.8559751049834908, Val g-mean: None\nEpoch: 198, Train loss: 0.3554686202201259, Train g-mean: 0.8548502456950301, Val g-mean: None\nEpoch: 199, Train loss: 0.362573541611697, Train g-mean: 0.8546925289044587, Val g-mean: None\n"
        }
      ],
      "source": [
        "pipeline = Pipeline(steps=[], classifier=classifier, optimizer=optimizer, criterion=criterion, max_epochs=200, fading_factor=0.9999)\n",
        "pipeline.train(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "  def evaluate(pipeline):\n",
        "    train_gmean, train_recalls = pipeline.evaluate(X_train, y_train)\n",
        "    test_gmean, test_recalls = pipeline.evaluate(X_test, y_test)\n",
        "    print('Epoch: {}'.format(pipeline.epoch))\n",
        "    print('Train g-mean: {}, recalls: {}'.format(train_gmean.item(), train_recalls))\n",
        "    print('Test g-mean: {}, recalls: {}'.format(test_gmean.item(), test_recalls))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Last classifier\nEpoch: 199\nTrain g-mean: 0.8546925289044587, recalls: [0.75760684 0.96421955]\nTest g-mean: 0.5702050157433335, recalls: [0.47840081 0.67962627]\n"
        }
      ],
      "source": [
        "print('Last classifier')\n",
        "evaluate(pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "if pipeline.has_validation():\n",
        "    print('Best classifier')\n",
        "    pipeline.load()\n",
        "    evaluate(pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "L_t4Gh43GYWl"
      },
      "outputs": [],
      "source": []
    }
  ]
}